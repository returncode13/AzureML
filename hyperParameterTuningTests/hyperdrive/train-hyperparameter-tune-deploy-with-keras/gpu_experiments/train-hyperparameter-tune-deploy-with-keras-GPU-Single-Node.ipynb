{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/NotebookVM/how-to-use-azureml/training-with-deep-learning/train-hyperparameter-tune-deploy-with-keras/train-hyperparameter-tune-deploy-with-keras.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "bf74d2e9-2708-49b1-934b-e0ede342f475"
    }
   },
   "source": [
    "# Training, hyperparameter tune, and deploy with Keras\n",
    "\n",
    "## Introduction\n",
    "This tutorial shows how to train a simple deep neural network using the MNIST dataset and Keras on Azure Machine Learning. MNIST is a popular dataset consisting of 70,000 grayscale images. Each image is a handwritten digit of `28x28` pixels, representing number from 0 to 9. The goal is to create a multi-class classifier to identify the digit each image represents, and deploy it as a web service in Azure.\n",
    "\n",
    "For more information about the MNIST dataset, please visit [Yan LeCun's website](http://yann.lecun.com/exdb/mnist/).\n",
    "\n",
    "## Prerequisite:\n",
    "* Understand the [architecture and terms](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture) introduced by Azure Machine Learning\n",
    "* If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, go through the [configuration notebook](../../../configuration.ipynb) to:\n",
    "    * install the AML SDK\n",
    "    * create a workspace and its configuration file (`config.json`)\n",
    "* For local scoring test, you will also need to have `tensorflow` and `keras` installed in the current Jupyter kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started. First let's import some Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "c377ea0c-0cd9-4345-9be2-e20fb29c94c3"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbpresent": {
     "id": "edaa7f2f-2439-4148-b57a-8c794c0945ec"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.2.0\n"
     ]
    }
   ],
   "source": [
    "import azureml\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize workspace\n",
    "Initialize a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) object from the existing workspace you created in the Prerequisites step. `Workspace.from_config()` creates a workspace object from the details stored in `config.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: cirrustest2\n",
      "Azure region: southcentralus\n",
      "Subscription id: c1d0a0ea-bf6e-4c1c-8b55-f1bdb0208df8\n",
      "Resource group: awe-cirrus-rg\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "59f52294-4a25-4c92-bab8-3b07f0f44d15"
    }
   },
   "source": [
    "## Create an Azure ML experiment\n",
    "Let's create an experiment named \"keras-mnist\" and a folder to hold the training scripts. The script runs will be recorded under the experiment in Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbpresent": {
     "id": "bc70f780-c240-4779-96f3-bc5ef9a37d59"
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "script_folder = './keras-mnist-gpu'\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "\n",
    "exp = Experiment(workspace=ws, name='tf-cluster-multi-gpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore data\n",
    "\n",
    "Before you train a model, you need to understand the data that you are using to train it. In this section you learn how to:\n",
    "\n",
    "* Download the MNIST dataset\n",
    "* Display some sample images\n",
    "\n",
    "### Download the MNIST dataset\n",
    "\n",
    "Download the MNIST dataset and save the files into a `data` directory locally.  Images and labels for both training and testing are downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/mnt/batch/tasks/shared/LS_root/mounts/clusters/sn-nc12-lab/code/Users/supanaesw/hyperParameterTuningTests/hyperdrive/train-hyperparameter-tune-deploy-with-keras/gpu_experiments/data/test-labels.gz',\n",
       " <http.client.HTTPMessage at 0x7f9f76dcb2b0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "# data_folder = os.path.join(os.getcwd(), 'data')\n",
    "# os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "# urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz', filename=os.path.join(data_folder, 'train-images.gz'))\n",
    "# urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz', filename=os.path.join(data_folder, 'train-labels.gz'))\n",
    "# urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz', filename=os.path.join(data_folder, 'test-images.gz'))\n",
    "# urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz', filename=os.path.join(data_folder, 'test-labels.gz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display some sample images\n",
    "\n",
    "Load the compressed files into `numpy` arrays. Then use `matplotlib` to plot 30 random images from the dataset with their labels above them. Note this step requires a `load_data` function that's included in an `utils.py` file. This file is included in the sample folder. Please make sure it is placed in the same folder as this notebook. The `load_data` function simply parses the compressed files into numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 30 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make sure utils.py is in the same directory as this code\n",
    "from utils import load_data, one_hot_encode\n",
    "\n",
    "# # note we also shrink the intensity values (X) from 0-255 to 0-1. This helps the model converge faster.\n",
    "# X_train = load_data(os.path.join(data_folder, 'train-images.gz'), False) / 255.0\n",
    "# X_test = load_data(os.path.join(data_folder, 'test-images.gz'), False) / 255.0\n",
    "# y_train = load_data(os.path.join(data_folder, 'train-labels.gz'), True).reshape(-1)\n",
    "# y_test = load_data(os.path.join(data_folder, 'test-labels.gz'), True).reshape(-1)\n",
    "\n",
    "# # now let's show some randomly chosen images from the training set.\n",
    "# count = 0\n",
    "# sample_size = 30\n",
    "# plt.figure(figsize = (16, 6))\n",
    "# for i in np.random.permutation(X_train.shape[0])[:sample_size]:\n",
    "#     count = count + 1\n",
    "#     plt.subplot(1, sample_size, count)\n",
    "#     plt.axhline('')\n",
    "#     plt.axvline('')\n",
    "#     plt.text(x=10, y=-10, s=y_train[i], fontsize=18)\n",
    "#     plt.imshow(X_train[i].reshape(28, 28), cmap=plt.cm.Greys)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have an idea of what these images look like and the expected prediction outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "defe921f-8097-44c3-8336-8af6700804a7"
    }
   },
   "source": [
    "## Create a FileDataset\n",
    "A FileDataset references one or multiple files in your datastores or public urls. The files can be of any format. **FileDataset provides you with the ability to download or mount the files to your compute. By creating a dataset, you create a reference to the data source location.** If you applied any subsetting transformations to the dataset, they will be stored in the dataset as well. The data remains in its existing location, so no extra storage cost is incurred. [Learn More](https://aka.ms/azureml/howto/createdatasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "# web_paths = [\n",
    "#             'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
    "#             'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
    "#             'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
    "#             'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'\n",
    "#             ]\n",
    "# dataset = Dataset.File.from_files(path = web_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `register()` method to register datasets to your workspace so they can be shared with others, reused across various experiments, and referred to by name in your training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataset.register(workspace = ws,\n",
    "#                            name = 'mnist dataset',\n",
    "#                            description='training and test dataset',\n",
    "#                            create_new_version=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azureml.core import Dataset, Datastore\n",
    "# datastore=Datastore.get(ws,'workspaceblobstore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(datastore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create or Attach existing AmlCompute\n",
    "You will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) for training your model. In this tutorial, you create `AmlCompute` as your training compute resource."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we could not find the cluster with the given name, then we will create a new cluster here. We will create an `AmlCompute` cluster of `STANDARD_NC6` GPU VMs. This process is broken down into 3 steps:\n",
    "1. create the configuration (this step is local and only takes a second)\n",
    "2. create the cluster (this step will take about **20 seconds**)\n",
    "3. provision the VMs to bring the cluster to the initial size (of 1 in this case). This step will take about **3-5 minutes** and is providing only sparse output in the process. Please make sure to wait until the call returns before moving to the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target\n",
      "{'currentNodeCount': 0, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2020-04-10T19:48:18.033000+00:00', 'errors': None, 'creationTime': '2020-04-10T19:09:52.985213+00:00', 'modifiedTime': '2020-04-10T19:10:08.904612+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT300S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC12'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster KEEP THE NAME BETWEEN 6-12 chars. else it fails\n",
    "cluster_name = \"sn-gpu-cls-NC12\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC12', \n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it uses the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "# use get_status() to get a detailed status for the current cluster. \n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have created the compute target, let's see what the workspace's `compute_targets` property returns. You should now see one entry named \"gpu-cluster\" of type `AmlCompute`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sn-gpu-cluster AmlCompute Succeeded\n",
      "sn-gpu-cls-NC12 AmlCompute Succeeded\n",
      "aa-gpucluster AmlCompute Succeeded\n",
      "aa20200411lab ComputeInstance Succeeded\n",
      "sn-nc12-lab ComputeInstance Succeeded\n",
      "aylab ComputeInstance Succeeded\n"
     ]
    }
   ],
   "source": [
    "compute_targets = ws.compute_targets\n",
    "for name, ct in compute_targets.items():\n",
    "    print(name, ct.type, ct.provisioning_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy the training files into the script folder\n",
    "The Keras training script is already created for you. You can simply copy it into the script folder, together with the utility library used to load compressed data file into numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./keras-mnist-gpu/unet.py'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# the training logic is in the keras_mnist.py file.\n",
    "shutil.copy('./keras_mnist-gpu.py', script_folder)\n",
    "\n",
    "# the utils.py just helps loading data from the downloaded MNIST dataset into numpy arrays.\n",
    "shutil.copy('./utils.py', script_folder)\n",
    "shutil.copy('./datagenerator.py', script_folder)\n",
    "shutil.copy('./unet.py', script_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "2039d2d5-aca6-4f25-a12f-df9ae6529cae"
    }
   },
   "source": [
    "## Construct neural network in Keras\n",
    "In the training script `keras_mnist.py`, it creates a very simple DNN (deep neural network), with just 2 hidden layers. The input layer has 28 * 28 = 784 neurons, each representing a pixel in an image. The first hidden layer has 300 neurons, and the second hidden layer has 100 neurons. The output layer has 10 neurons, each representing a targeted label from 0 to 9.\n",
    "\n",
    "![DNN](nn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure ML concepts  \n",
    "Please note the following three things in the code below:\n",
    "1. **The script accepts arguments using the argparse package**. In this case there is one argument `--data_folder` which specifies the FileDataset in which the script can find the MNIST data\n",
    "```\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--data_folder')\n",
    "```\n",
    "2. The script is accessing the Azure ML `Run` object by executing `run = Run.get_context()`. Further down the script is using the `run` to report the loss and accuracy at the end of each epoch via callback.\n",
    "```\n",
    "    run.log('Loss', log['loss'])\n",
    "    run.log('Accuracy', log['acc'])\n",
    "```\n",
    "3. When running the script on Azure ML, you can write files out to a folder `./outputs` that is relative to the root directory. This folder is specially tracked by Azure ML in the sense that any files written to that folder during script execution on the remote target will be picked up by Run History; these files (known as artifacts) will be available as part of the run history record."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell will print out the training code for you to inspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
      "# Licensed under the MIT License.\n",
      "\n",
      "import numpy as np\n",
      "import argparse\n",
      "import os\n",
      "import glob\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import tensorflow.keras\n",
      "from tensorflow.keras.models import  model_from_json\n",
      "from tensorflow.keras.callbacks import Callback\n",
      "\n",
      "import tensorflow as tf\n",
      "\n",
      "#from azureml.core import Run\n",
      "from utils import load_data, one_hot_encode, build_model_gpu_unet,create_data\n",
      "from datagenerator import *\n",
      "import math\n",
      "from tensorflow.python.client import device_lib\n",
      "\n",
      "\n",
      "print(\"Keras version:\", tensorflow.keras.__version__)\n",
      "print(\"Tensorflow version:\", tf.__version__)\n",
      "print(device_lib.list_local_devices())\n",
      "\n",
      "parser = argparse.ArgumentParser()\n",
      "parser.add_argument('--data-folder', type=str, dest='data_folder', help='data folder mounting point')\n",
      "parser.add_argument('--batch-size', type=int, dest='batch_size', default=50, help='mini batch size for training')\n",
      "parser.add_argument('--first-layer-neurons', type=int, dest='n_hidden_1', default=100,\n",
      "                    help='# of neurons in the first layer')\n",
      "parser.add_argument('--second-layer-neurons', type=int, dest='n_hidden_2', default=100,\n",
      "                    help='# of neurons in the second layer')\n",
      "parser.add_argument('--learning-rate', type=float, dest='learning_rate', default=0.001, help='learning rate')\n",
      "\n",
      "args = parser.parse_args()\n",
      "\n",
      "data_folder = args.data_folder\n",
      "\n",
      "print('training dataset is stored here:', data_folder)\n",
      "\n",
      "# X_train_path = glob.glob(os.path.join(data_folder, '**/train-images-idx3-ubyte.gz'), recursive=True)[0]\n",
      "# X_test_path = glob.glob(os.path.join(data_folder, '**/t10k-images-idx3-ubyte.gz'), recursive=True)[0]\n",
      "# y_train_path = glob.glob(os.path.join(data_folder, '**/train-labels-idx1-ubyte.gz'), recursive=True)[0]\n",
      "# y_test_path = glob.glob(os.path.join(data_folder, '**/t10k-labels-idx1-ubyte.gz'), recursive=True)[0]\n",
      "\n",
      "# X_train = load_data(X_train_path, False) / 255.0\n",
      "# X_test = load_data(X_test_path, False) / 255.0\n",
      "# y_train = load_data(y_train_path, True).reshape(-1)\n",
      "# y_test = load_data(y_test_path, True).reshape(-1)\n",
      "X_train,y_train,X_test,y_test=create_data(no_samples=5000)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "training_set_size = X_train.shape[0]\n",
      "\n",
      "n_inputs = 28 * 28\n",
      "n_h1 = args.n_hidden_1\n",
      "n_h2 = args.n_hidden_2\n",
      "n_outputs = 10\n",
      "n_epochs = 20\n",
      "batch_size = args.batch_size\n",
      "learning_rate = args.learning_rate\n",
      "\n",
      "#y_train = one_hot_encode(y_train, n_outputs)\n",
      "#y_test = one_hot_encode(y_test, n_outputs)\n",
      "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, sep='\\n')\n",
      "\n",
      "#set up for gpu\n",
      "# strategy=tf.distribute.MirroredStrategy()\n",
      "# with strategy.scope():\n",
      "#     # Build a simple MLP model\n",
      "#     model = Sequential()\n",
      "#     # first hidden layer\n",
      "#     model.add(Dense(n_h1, activation='relu', input_shape=(n_inputs,)))\n",
      "#     # second hidden layer\n",
      "#     model.add(Dense(n_h2, activation='relu'))\n",
      "#     # output layer\n",
      "#     model.add(Dense(n_outputs, activation='softmax'))\n",
      "#     model.compile(loss='categorical_crossentropy',\n",
      "#                   optimizer=RMSprop(lr=learning_rate),\n",
      "#                   metrics=['accuracy'])\n",
      "\n",
      "model=build_model_gpu_unet()\n",
      "# start an Azure ML run\n",
      "run = Run.get_context()\n",
      "\n",
      "#get dataset generator for feeding in batches\n",
      "\n",
      "\n",
      "train_gen=DataGenerator(X=X_train,Y=y_train,batch_size=batch_size,shuffle=True)\n",
      "val_gen=DataGenerator(X=X_test,Y=y_test,batch_size=batch_size,shuffle=True)\n",
      "\n",
      "\n",
      " class LogRunMetrics(Callback):\n",
      "               \n",
      "#     # callback at the end of every epoch\n",
      "         def on_epoch_end(self, epoch, log):\n",
      "    #         # log a value repeated which creates a list\n",
      "            run.log('Loss', log['loss'])\n",
      "            run.log('Accuracy', log['accuracy'])\n",
      "\n",
      "\n",
      "# history = model.fit(X_train, y_train,\n",
      "#                     batch_size=batch_size,\n",
      "#                     epochs=n_epochs,\n",
      "#                     verbose=2,\n",
      "#                     validation_data=(X_test, y_test),\n",
      "#                     callbacks=[LogRunMetrics()])\n",
      "\n",
      "history = model.fit(train_gen,\n",
      "                    #batch_size=batch_size,\n",
      "                    steps_per_epoch=math.floor(len(X_train)/batch_size),\n",
      "                    epochs=n_epochs,\n",
      "                    verbose=2,\n",
      "                    validation_data=val_gen ,\n",
      "                    callbacks=[LogRunMetrics()])\n",
      "\n",
      "\n",
      "\n",
      "print(history)\n",
      "score = model.evaluate(X_test, y_test, verbose=0)\n",
      "\n",
      "# log a single value\n",
      "run.log(\"Final test loss\", score[0])\n",
      "print('Test loss:', score[0])\n",
      "\n",
      "#run.log('Final test accuracy', score[1])\n",
      "print('Test accuracy:', score[1])\n",
      "\n",
      "plt.figure(figsize=(6, 3))\n",
      "plt.title('MNIST with Keras MLP ({} epochs)'.format(n_epochs), fontsize=14)\n",
      "plt.plot(history.history['accuracy'], 'b-', label='Accuracy', lw=4, alpha=0.5)\n",
      "plt.plot(history.history['loss'], 'r--', label='Loss', lw=4, alpha=0.5)\n",
      "plt.legend(fontsize=12)\n",
      "plt.grid(True)\n",
      "\n",
      "# log an image\n",
      "run.log_image('Accuracy vs Loss', plot=plt)\n",
      "\n",
      "# create a ./outputs/model folder in the compute target\n",
      "# files saved in the \"./outputs\" folder are automatically uploaded into run history\n",
      "os.makedirs('./outputs/model', exist_ok=True)\n",
      "\n",
      "# serialize NN architecture to JSON\n",
      "model_json = model.to_json()\n",
      "# save model JSON\n",
      "with open('./outputs/model/model.json', 'w') as f:\n",
      "    f.write(model_json)\n",
      "# save model weights\n",
      "model.save_weights('./outputs/model/model.h5')\n",
      "print(\"model saved in ./outputs/model folder\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(script_folder, './keras_mnist-gpu.py'), 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TensorFlow estimator & add Keras\n",
    "Next, we construct an `azureml.train.dnn.TensorFlow` estimator object, use the `gpu-cluster` as compute target, and pass the mount-point of the datastore to the training code as a parameter.\n",
    "The TensorFlow estimator is providing a simple way of launching a TensorFlow training job on a compute target. It will automatically provide a docker image that has TensorFlow installed. In this case, we add `keras` package (for the Keras framework obviously), and `matplotlib` package for plotting a \"Loss vs. Accuracy\" chart and record it in run history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/http/yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
       " '/http/yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
       " '/http/yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
       " '/http/yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset = Dataset.get_by_name(ws, 'mnist dataset')\n",
    "\n",
    "# # list the files referenced by mnist dataset\n",
    "# dataset.to_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "script_params = {\n",
    "   # '--data-folder': \"dummyfolder\",\n",
    "    '--batch-size': 50,\n",
    "#     '--first-layer-neurons': 300,\n",
    "#     '--second-layer-neurons': 100,\n",
    "#     '--learning-rate': 0.001\n",
    "    '--epochs':20\n",
    "}\n",
    "\n",
    "#https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/training-with-deep-learning/how-to-use-estimator/how-to-use-estimator.ipynb\n",
    "\n",
    "est = Estimator(source_directory=script_folder,\n",
    "                 script_params=script_params,\n",
    "                 compute_target=compute_target, \n",
    "                 entry_script='keras_mnist-gpu.py', \n",
    "                 #pip_packages=['tensorflow==2.0','keras==2.2.5','azureml-dataprep[pandas,fuse]','matplotlib'],\n",
    "                 #framework_version=2.0,\n",
    "                # environ=some_file,\n",
    "                #use_docker=True,\n",
    "                #image_registry_details=container_registry,\n",
    "                custom_docker_image=\"returncode13/tf-gpu-test:v2\",\n",
    "                 use_gpu=True,\n",
    "                user_managed=True\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit job to run\n",
    "Submit the estimator to the Azure ML experiment to kick off the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = exp.submit(est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor the Run\n",
    "As the Run is executed, it will go through the following stages:\n",
    "1. **Preparing: A docker image is created matching the Python environment specified by the TensorFlow estimator and it will be uploaded to the workspace's Azure Container Registry**. This step will only happen once for each Python environment -- the container will then be cached for subsequent runs. Creating and uploading the image takes about **5 minutes**. While the job is preparing, logs are streamed to the run history and can be viewed to monitor the progress of the image creation.\n",
    "\n",
    "2. **Scaling**: If the compute needs to be scaled up (i.e. the AmlCompute cluster requires more nodes to execute the run than currently available), the cluster will attempt to scale up in order to make the required amount of nodes available. Scaling typically takes about **5 minutes**.\n",
    "\n",
    "3. **Running: All scripts in the script folder are uploaded to the compute target, data stores are mounted/copied and the `entry_script` is executed**. While the job is running, stdout and the `./logs` folder are streamed to the run history and can be viewed to monitor the progress of the run.\n",
    "\n",
    "4. **Post-Processing**: The `./outputs` folder of the run is copied over to the run history\n",
    "\n",
    "There are multiple ways to check the progress of a running job. We can use a Jupyter notebook widget. \n",
    "\n",
    "**Note: The widget will automatically update ever 10-15 seconds, always showing you the most up-to-date information about the run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96ba696cb954041bab3260d504f9656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Running\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/tf-cluster-multi-gpu/runs/tf-cluster-multi-gpu_1586637483_41828672?wsid=/subscriptions/c1d0a0ea-bf6e-4c1c-8b55-f1bdb0208df8/resourcegroups/awe-cirrus-rg/workspaces/cirrustest2\", \"run_id\": \"tf-cluster-multi-gpu_1586637483_41828672\", \"run_properties\": {\"run_id\": \"tf-cluster-multi-gpu_1586637483_41828672\", \"created_utc\": \"2020-04-11T20:38:07.565266Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"15fc5b86-e726-428a-afdf-2d643e25df4b\", \"azureml.git.repository_uri\": \"https://github.com/returncode13/AzureML.git\", \"mlflow.source.git.repoURL\": \"https://github.com/returncode13/AzureML.git\", \"azureml.git.branch\": \"dev\", \"mlflow.source.git.branch\": \"dev\", \"azureml.git.commit\": \"4cb1d1a63ee9d666f9b31647c6a1545e0c7ac969\", \"mlflow.source.git.commit\": \"4cb1d1a63ee9d666f9b31647c6a1545e0c7ac969\", \"azureml.git.dirty\": \"True\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":1}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": null, \"status\": \"Running\", \"log_files\": {\"azureml-logs/55_azureml-execution-tvmps_b822616ab430925d5a2e6f9f15b2b7b54543eed65414c1dfaec6e96f4ee3e50b_d.txt\": \"https://cirrustest28363900696.blob.core.windows.net/azureml/ExperimentRun/dcid.tf-cluster-multi-gpu_1586637483_41828672/azureml-logs/55_azureml-execution-tvmps_b822616ab430925d5a2e6f9f15b2b7b54543eed65414c1dfaec6e96f4ee3e50b_d.txt?sv=2019-02-02&sr=b&sig=nCYNC9X5ZZp%2B%2BMlIcKjCgyNYhBOYFuJhq%2FQ7BQwsx0U%3D&st=2020-04-11T20%3A33%3A18Z&se=2020-04-12T04%3A43%3A18Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_b822616ab430925d5a2e6f9f15b2b7b54543eed65414c1dfaec6e96f4ee3e50b_d.txt\": \"https://cirrustest28363900696.blob.core.windows.net/azureml/ExperimentRun/dcid.tf-cluster-multi-gpu_1586637483_41828672/azureml-logs/65_job_prep-tvmps_b822616ab430925d5a2e6f9f15b2b7b54543eed65414c1dfaec6e96f4ee3e50b_d.txt?sv=2019-02-02&sr=b&sig=t2H%2B8svpwv4hcG1pKZc9RlNWnkEN%2BnocB2nxSfEl4KY%3D&st=2020-04-11T20%3A33%3A18Z&se=2020-04-12T04%3A43%3A18Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://cirrustest28363900696.blob.core.windows.net/azureml/ExperimentRun/dcid.tf-cluster-multi-gpu_1586637483_41828672/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=TLrIzC3woriZ5FRhk9414EuR3jLvYdo70mmFPbS3ruk%3D&st=2020-04-11T20%3A33%3A18Z&se=2020-04-12T04%3A43%3A18Z&sp=r\", \"azureml-logs/process_info.json\": \"https://cirrustest28363900696.blob.core.windows.net/azureml/ExperimentRun/dcid.tf-cluster-multi-gpu_1586637483_41828672/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=vwLgV0s6ywZncKR%2BlTOlfadCJd1xzaBM8%2FJ0zZ6dZ40%3D&st=2020-04-11T20%3A33%3A18Z&se=2020-04-12T04%3A43%3A18Z&sp=r\", \"azureml-logs/process_status.json\": \"https://cirrustest28363900696.blob.core.windows.net/azureml/ExperimentRun/dcid.tf-cluster-multi-gpu_1586637483_41828672/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=Biy8t8667cqJkUQMyfa79PKGs5f%2B7s%2BYOZYis83fi5g%3D&st=2020-04-11T20%3A33%3A18Z&se=2020-04-12T04%3A43%3A18Z&sp=r\", \"logs/azureml/455_azureml.log\": \"https://cirrustest28363900696.blob.core.windows.net/azureml/ExperimentRun/dcid.tf-cluster-multi-gpu_1586637483_41828672/logs/azureml/455_azureml.log?sv=2019-02-02&sr=b&sig=qb6bm8Mgf4CAm7C0Z58xTPmqY4p9t%2BdF57lB2NUMTB0%3D&st=2020-04-11T20%3A33%3A18Z&se=2020-04-12T04%3A43%3A18Z&sp=r\", \"logs/azureml/job_prep_azureml.log\": \"https://cirrustest28363900696.blob.core.windows.net/azureml/ExperimentRun/dcid.tf-cluster-multi-gpu_1586637483_41828672/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=fRIDWpbMOA5MUamILj4Tc3RLy5Wt%2BRXhi71bQ%2FV2I%2Fk%3D&st=2020-04-11T20%3A33%3A18Z&se=2020-04-12T04%3A43%3A18Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/process_info.json\", \"azureml-logs/process_status.json\", \"logs/azureml/job_prep_azureml.log\"], [\"azureml-logs/55_azureml-execution-tvmps_b822616ab430925d5a2e6f9f15b2b7b54543eed65414c1dfaec6e96f4ee3e50b_d.txt\"], [\"azureml-logs/65_job_prep-tvmps_b822616ab430925d5a2e6f9f15b2b7b54543eed65414c1dfaec6e96f4ee3e50b_d.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"logs/azureml/455_azureml.log\"]], \"run_duration\": \"0:05:11\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"Loss\", \"run_id\": \"tf-cluster-multi-gpu_1586637483_41828672\", \"categories\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], \"series\": [{\"data\": [0.8612848231196404, 0.2544753961265087, 0.16930606797337533, 0.13404045790433883, 0.11144404038786888, 0.09654842272400856, 0.08667242176830768, 0.07974897757172585, 0.07460214287042617, 0.07064146853983402, 0.06746331214904785, 0.06481637537479401, 0.06257621053606272, 0.06065903708338737, 0.05893784236162901, 0.05736836705356836]}]}, {\"name\": \"Accuracy\", \"run_id\": \"tf-cluster-multi-gpu_1586637483_41828672\", \"categories\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], \"series\": [{\"data\": [1.525878978725359e-08, 2.7465819840699623e-08, 2.7465819840699623e-08, 2.7465819840699623e-08, 2.7465819840699623e-08, 2.7465819840699623e-08, 2.7465819840699623e-08, 2.4414061883248905e-08, 2.7465819840699623e-08, 2.4414061883248905e-08, 2.7465819840699623e-08, 2.7465819840699623e-08, 2.7465819840699623e-08, 2.7465819840699623e-08, 2.7465819840699623e-08, 2.7465819840699623e-08]}]}], \"run_logs\": \"2020-04-11 20:38:36,146|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'snapshotProject': True, 'only_in_process_features': True, 'skip_track_logs_dir': True}, track_folders: None, deny_list: None, directories_to_watch: []\\n2020-04-11 20:38:36,146|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: batchai\\n2020-04-11 20:38:36,152|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Failed to import pyspark with error: No module named 'pyspark'\\n2020-04-11 20:38:36,152|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2020-04-11 20:38:36,737|azureml.core._experiment_method|DEBUG|Trying to register submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveRunConfig'>\\n2020-04-11 20:38:36,737|azureml.core._experiment_method|DEBUG|Registered submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveRunConfig'>\\n2020-04-11 20:38:36,738|azureml.core._experiment_method|DEBUG|Trying to register submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveConfig'>\\n2020-04-11 20:38:36,738|azureml.core._experiment_method|DEBUG|Registered submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveConfig'>\\n2020-04-11 20:38:36,738|azureml.core.run|DEBUG|Adding new factory <function HyperDriveRun._from_run_dto at 0x7f880aaa5158> for run source hyperdrive\\n2020-04-11 20:38:37,109|azureml.core.run|DEBUG|Adding new factory <function PipelineRun._from_dto at 0x7f88285c9510> for run source azureml.PipelineRun\\n2020-04-11 20:38:37,114|azureml.core.run|DEBUG|Adding new factory <function StepRun._from_reused_dto at 0x7f88285c9f28> for run source azureml.ReusedStepRun\\n2020-04-11 20:38:37,119|azureml.core.run|DEBUG|Adding new factory <function StepRun._from_dto at 0x7f88285c9ea0> for run source azureml.StepRun\\n2020-04-11 20:38:37,123|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7f880ac629d8> for run source azureml.scriptrun\\n2020-04-11 20:38:37,125|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2020-04-11 20:38:37,130|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2020-04-11 20:38:37,131|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2020-04-11 20:38:37,131|azureml.core.authentication|DEBUG|Time to expire 1814369.868107 seconds\\n2020-04-11 20:38:37,132|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-04-11 20:38:37,132|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-04-11 20:38:37,132|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-04-11 20:38:37,132|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-04-11 20:38:37,162|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-04-11 20:38:37,162|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-04-11 20:38:37,163|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-04-11 20:38:37,167|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2020-04-11 20:38:37,174|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2020-04-11 20:38:37,178|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2020-04-11 20:38:37,182|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2020-04-11 20:38:37,187|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2020-04-11 20:38:37,187|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.RunClient.get-async:False|DEBUG|[START]\\n2020-04-11 20:38:37,187|msrest.service_client|DEBUG|Accept header absent and forced to application/json\\n2020-04-11 20:38:37,188|msrest.http_logger|DEBUG|Request URL: 'https://southcentralus.experiments.azureml.net/history/v1.0/subscriptions/c1d0a0ea-bf6e-4c1c-8b55-f1bdb0208df8/resourceGroups/awe-cirrus-rg/providers/Microsoft.MachineLearningServices/workspaces/cirrustest2/experiments/tf-cluster-multi-gpu/runs/tf-cluster-multi-gpu_1586637483_41828672'\\n2020-04-11 20:38:37,188|msrest.http_logger|DEBUG|Request method: 'GET'\\n2020-04-11 20:38:37,188|msrest.http_logger|DEBUG|Request headers:\\n2020-04-11 20:38:37,188|msrest.http_logger|DEBUG|    'Accept': 'application/json'\\n2020-04-11 20:38:37,188|msrest.http_logger|DEBUG|    'Content-Type': 'application/json; charset=utf-8'\\n2020-04-11 20:38:37,188|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '91ec236b-a217-4b40-9c21-81215b1970ce'\\n2020-04-11 20:38:37,188|msrest.http_logger|DEBUG|    'request-id': '91ec236b-a217-4b40-9c21-81215b1970ce'\\n2020-04-11 20:38:37,188|msrest.http_logger|DEBUG|    'User-Agent': 'python/3.6.9 (Linux-4.15.0-1067-azure-x86_64-with-Ubuntu-18.04-bionic) msrest/0.6.13 azureml._restclient/core.1.2.0 azureml-sdk-core/1.2.0'\\n2020-04-11 20:38:37,188|msrest.http_logger|DEBUG|Request body:\\n2020-04-11 20:38:37,189|msrest.http_logger|DEBUG|None\\n2020-04-11 20:38:37,189|msrest.universal_http|DEBUG|Configuring redirects: allow=True, max=30\\n2020-04-11 20:38:37,189|msrest.universal_http|DEBUG|Configuring request: timeout=100, verify=True, cert=None\\n2020-04-11 20:38:37,189|msrest.universal_http|DEBUG|Configuring proxies: ''\\n2020-04-11 20:38:37,189|msrest.universal_http|DEBUG|Evaluate proxies against ENV settings: True\\n2020-04-11 20:38:37,392|msrest.http_logger|DEBUG|Response status: 200\\n2020-04-11 20:38:37,392|msrest.http_logger|DEBUG|Response headers:\\n2020-04-11 20:38:37,392|msrest.http_logger|DEBUG|    'Date': 'Sat, 11 Apr 2020 20:38:37 GMT'\\n2020-04-11 20:38:37,392|msrest.http_logger|DEBUG|    'Content-Type': 'application/json; charset=utf-8'\\n2020-04-11 20:38:37,392|msrest.http_logger|DEBUG|    'Transfer-Encoding': 'chunked'\\n2020-04-11 20:38:37,392|msrest.http_logger|DEBUG|    'Connection': 'keep-alive'\\n2020-04-11 20:38:37,392|msrest.http_logger|DEBUG|    'Vary': 'Accept-Encoding'\\n2020-04-11 20:38:37,392|msrest.http_logger|DEBUG|    'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d'\\n2020-04-11 20:38:37,393|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '91ec236b-a217-4b40-9c21-81215b1970ce'\\n2020-04-11 20:38:37,393|msrest.http_logger|DEBUG|    'x-ms-client-session-id': ''\\n2020-04-11 20:38:37,393|msrest.http_logger|DEBUG|    'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'\\n2020-04-11 20:38:37,393|msrest.http_logger|DEBUG|    'Content-Encoding': 'gzip'\\n2020-04-11 20:38:37,393|msrest.http_logger|DEBUG|Response content:\\n2020-04-11 20:38:37,393|msrest.http_logger|DEBUG|{\\n  \\\"runNumber\\\": 24,\\n  \\\"rootRunId\\\": \\\"tf-cluster-multi-gpu_1586637483_41828672\\\",\\n  \\\"experimentId\\\": \\\"0a007c77-c7ae-4081-9f85-305a0b3f46a2\\\",\\n  \\\"createdUtc\\\": \\\"2020-04-11T20:38:07.5652666+00:00\\\",\\n  \\\"createdBy\\\": {\\n    \\\"userObjectId\\\": \\\"ee2572f8-4cee-4eb2-9277-177851607a9b\\\",\\n    \\\"userPuId\\\": \\\"10033FFFAF51E5BA\\\",\\n    \\\"userIdp\\\": null,\\n    \\\"userAltSecId\\\": null,\\n    \\\"userIss\\\": \\\"https://sts.windows.net/964e6f01-cb76-4800-842f-9cd7caa564c1/\\\",\\n    \\\"userTenantId\\\": \\\"964e6f01-cb76-4800-842f-9cd7caa564c1\\\",\\n    \\\"userName\\\": \\\"Anand Eswara\\\"\\n  },\\n  \\\"userId\\\": \\\"ee2572f8-4cee-4eb2-9277-177851607a9b\\\",\\n  \\\"token\\\": null,\\n  \\\"tokenExpiryTimeUtc\\\": null,\\n  \\\"error\\\": null,\\n  \\\"warnings\\\": null,\\n  \\\"revision\\\": 7,\\n  \\\"runUuid\\\": \\\"9be7af66-9ccc-44a2-9476-23748f535434\\\",\\n  \\\"parentRunUuid\\\": null,\\n  \\\"rootRunUuid\\\": \\\"9be7af66-9ccc-44a2-9476-23748f535434\\\",\\n  \\\"runId\\\": \\\"tf-cluster-multi-gpu_1586637483_41828672\\\",\\n  \\\"parentRunId\\\": null,\\n  \\\"status\\\": \\\"Running\\\",\\n  \\\"startTimeUtc\\\": \\\"2020-04-11T20:38:25.8230788+00:00\\\",\\n  \\\"endTimeUtc\\\": null,\\n  \\\"heartbeatEnabled\\\": false,\\n  \\\"options\\\": {\\n    \\\"generateDataContainerIdIfNotSpecified\\\": true\\n  },\\n  \\\"name\\\": null,\\n  \\\"dataContainerId\\\": \\\"dcid.tf-cluster-multi-gpu_1586637483_41828672\\\",\\n  \\\"description\\\": null,\\n  \\\"hidden\\\": false,\\n  \\\"runType\\\": \\\"azureml.scriptrun\\\",\\n  \\\"properties\\\": {\\n    \\\"_azureml.ComputeTargetType\\\": \\\"amlcompute\\\",\\n    \\\"ContentSnapshotId\\\": \\\"15fc5b86-e726-428a-afdf-2d643e25df4b\\\",\\n    \\\"azureml.git.repository_uri\\\": \\\"https://github.com/returncode13/AzureML.git\\\",\\n    \\\"mlflow.source.git.repoURL\\\": \\\"https://github.com/returncode13/AzureML.git\\\",\\n    \\\"azureml.git.branch\\\": \\\"dev\\\",\\n    \\\"mlflow.source.git.branch\\\": \\\"dev\\\",\\n    \\\"azureml.git.commit\\\": \\\"4cb1d1a63ee9d666f9b31647c6a1545e0c7ac969\\\",\\n    \\\"mlflow.source.git.commit\\\": \\\"4cb1d1a63ee9d666f9b31647c6a1545e0c7ac969\\\",\\n    \\\"azureml.git.dirty\\\": \\\"True\\\",\\n    \\\"ProcessInfoFile\\\": \\\"azureml-logs/process_info.json\\\",\\n    \\\"ProcessStatusFile\\\": \\\"azureml-logs/process_status.json\\\"\\n  },\\n  \\\"scriptName\\\": \\\"keras_mnist-gpu.py\\\",\\n  \\\"target\\\": \\\"sn-gpu-cls-NC12\\\",\\n  \\\"uniqueChildRunComputeTargets\\\": [],\\n  \\\"tags\\\": {\\n    \\\"_aml_system_ComputeTargetStatus\\\": \\\"{\\\\\\\"AllocationState\\\\\\\":\\\\\\\"steady\\\\\\\",\\\\\\\"PreparingNodeCount\\\\\\\":0,\\\\\\\"RunningNodeCount\\\\\\\":0,\\\\\\\"CurrentNodeCount\\\\\\\":1}\\\"\\n  },\\n  \\\"inputDatasets\\\": [],\\n  \\\"runDefinition\\\": null,\\n  \\\"createdFrom\\\": null,\\n  \\\"cancelUri\\\": \\\"https://southcentralus.experiments.azureml.net/execution/v1.0/subscriptions/c1d0a0ea-bf6e-4c1c-8b55-f1bdb0208df8/resourceGroups/awe-cirrus-rg/providers/Microsoft.MachineLearningServices/workspaces/cirrustest2/experiments/tf-cluster-multi-gpu/runId/tf-cluster-multi-gpu_1586637483_41828672/cancel\\\",\\n  \\\"completeUri\\\": null,\\n  \\\"diagnosticsUri\\\": \\\"https://southcentralus.experiments.azureml.net/execution/v1.0/subscriptions/c1d0a0ea-bf6e-4c1c-8b55-f1bdb0208df8/resourceGroups/awe-cirrus-rg/providers/Microsoft.MachineLearningServices/workspaces/cirrustest2/experiments/tf-cluster-multi-gpu/runId/tf-cluster-multi-gpu_1586637483_41828672/diagnostics\\\",\\n  \\\"computeRequest\\\": {\\n    \\\"nodeCount\\\": 1\\n  },\\n  \\\"retainForLifetimeOfWorkspace\\\": false,\\n  \\\"queueingInfo\\\": null\\n}\\n2020-04-11 20:38:37,398|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.RunClient.get-async:False|DEBUG|[STOP]\\n2020-04-11 20:38:37,399|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': '15fc5b86-e726-428a-afdf-2d643e25df4b', 'azureml.git.repository_uri': 'https://github.com/returncode13/AzureML.git', 'mlflow.source.git.repoURL': 'https://github.com/returncode13/AzureML.git', 'azureml.git.branch': 'dev', 'mlflow.source.git.branch': 'dev', 'azureml.git.commit': '4cb1d1a63ee9d666f9b31647c6a1545e0c7ac969', 'mlflow.source.git.commit': '4cb1d1a63ee9d666f9b31647c6a1545e0c7ac969', 'azureml.git.dirty': 'True', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2020-04-11 20:38:37,399|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2020-04-11 20:38:37,399|azureml|WARNING|Could not import azureml.mlflow or azureml.contrib.mlflow mlflow APIs will not run against AzureML services.  Add azureml-mlflow as a conda dependency for the run if this behavior is desired\\n2020-04-11 20:38:37,399|azureml.WorkerPool|DEBUG|[START]\\n2020-04-11 20:38:37,400|azureml.SendRunKillSignal|DEBUG|[START]\\n2020-04-11 20:38:37,400|azureml.RunStatusContext|DEBUG|[START]\\n2020-04-11 20:38:37,400|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunContextManager.RunStatusContext|DEBUG|[START]\\n2020-04-11 20:38:37,400|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2020-04-11 20:38:37,400|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2020-04-11 20:38:37,400|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/cirrustest2/azureml/tf-cluster-multi-gpu_1586637483_41828672/mounts/workspaceblobstore/azureml/tf-cluster-multi-gpu_1586637483_41828672\\n2020-04-11 20:38:37,400|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2020-04-11 20:38:37,400|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /mnt/batch/tasks/shared/LS_root/jobs/cirrustest2/azureml/tf-cluster-multi-gpu_1586637483_41828672/mounts/workspaceblobstore/azureml/tf-cluster-multi-gpu_1586637483_41828672\\n2020-04-11 20:39:07,126|azureml.core.authentication|DEBUG|Time to expire 1814339.87388 seconds\\n2020-04-11 20:39:12,230|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-04-11 20:39:12,231|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-04-11 20:39:12,231|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-04-11 20:39:12,231|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-04-11 20:39:12,231|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-04-11 20:39:12,231|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-04-11 20:39:12,232|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-04-11 20:39:12,236|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2020-04-11 20:39:12,237|azureml._run_impl.run_history_facade|DEBUG|Created a static thread pool for RunHistoryFacade class\\n2020-04-11 20:39:12,241|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2020-04-11 20:39:12,245|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2020-04-11 20:39:12,252|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2020-04-11 20:39:12,257|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2020-04-11 20:39:12,257|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.RunClient.get-async:False|DEBUG|[START]\\n2020-04-11 20:39:12,258|msrest.service_client|DEBUG|Accept header absent and forced to application/json\\n2020-04-11 20:39:12,258|msrest.http_logger|DEBUG|Request URL: 'https://southcentralus.experiments.azureml.net/history/v1.0/subscriptions/c1d0a0ea-bf6e-4c1c-8b55-f1bdb0208df8/resourceGroups/awe-cirrus-rg/providers/Microsoft.MachineLearningServices/workspaces/cirrustest2/experiments/tf-cluster-multi-gpu/runs/tf-cluster-multi-gpu_1586637483_41828672'\\n2020-04-11 20:39:12,258|msrest.http_logger|DEBUG|Request method: 'GET'\\n2020-04-11 20:39:12,258|msrest.http_logger|DEBUG|Request headers:\\n2020-04-11 20:39:12,258|msrest.http_logger|DEBUG|    'Accept': 'application/json'\\n2020-04-11 20:39:12,258|msrest.http_logger|DEBUG|    'Content-Type': 'application/json; charset=utf-8'\\n2020-04-11 20:39:12,258|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '04fe4b9e-f444-46f6-a3ee-dc6c13cdfa16'\\n2020-04-11 20:39:12,258|msrest.http_logger|DEBUG|    'request-id': '04fe4b9e-f444-46f6-a3ee-dc6c13cdfa16'\\n2020-04-11 20:39:12,258|msrest.http_logger|DEBUG|    'User-Agent': 'python/3.6.9 (Linux-4.15.0-1067-azure-x86_64-with-Ubuntu-18.04-bionic) msrest/0.6.13 azureml._restclient/core.1.2.0 azureml-sdk-core/1.2.0'\\n2020-04-11 20:39:12,258|msrest.http_logger|DEBUG|Request body:\\n2020-04-11 20:39:12,259|msrest.http_logger|DEBUG|None\\n2020-04-11 20:39:12,259|msrest.universal_http|DEBUG|Configuring redirects: allow=True, max=30\\n2020-04-11 20:39:12,259|msrest.universal_http|DEBUG|Configuring request: timeout=100, verify=True, cert=None\\n2020-04-11 20:39:12,259|msrest.universal_http|DEBUG|Configuring proxies: ''\\n2020-04-11 20:39:12,259|msrest.universal_http|DEBUG|Evaluate proxies against ENV settings: True\\n2020-04-11 20:39:12,310|msrest.http_logger|DEBUG|Response status: 200\\n2020-04-11 20:39:12,310|msrest.http_logger|DEBUG|Response headers:\\n2020-04-11 20:39:12,310|msrest.http_logger|DEBUG|    'Date': 'Sat, 11 Apr 2020 20:39:12 GMT'\\n2020-04-11 20:39:12,310|msrest.http_logger|DEBUG|    'Content-Type': 'application/json; charset=utf-8'\\n2020-04-11 20:39:12,310|msrest.http_logger|DEBUG|    'Transfer-Encoding': 'chunked'\\n2020-04-11 20:39:12,310|msrest.http_logger|DEBUG|    'Connection': 'keep-alive'\\n2020-04-11 20:39:12,310|msrest.http_logger|DEBUG|    'Vary': 'Accept-Encoding'\\n2020-04-11 20:39:12,310|msrest.http_logger|DEBUG|    'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d'\\n2020-04-11 20:39:12,311|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '04fe4b9e-f444-46f6-a3ee-dc6c13cdfa16'\\n2020-04-11 20:39:12,311|msrest.http_logger|DEBUG|    'x-ms-client-session-id': ''\\n2020-04-11 20:39:12,311|msrest.http_logger|DEBUG|    'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'\\n2020-04-11 20:39:12,311|msrest.http_logger|DEBUG|    'Content-Encoding': 'gzip'\\n2020-04-11 20:39:12,311|msrest.http_logger|DEBUG|Response content:\\n2020-04-11 20:39:12,311|msrest.http_logger|DEBUG|{\\n  \\\"runNumber\\\": 24,\\n  \\\"rootRunId\\\": \\\"tf-cluster-multi-gpu_1586637483_41828672\\\",\\n  \\\"experimentId\\\": \\\"0a007c77-c7ae-4081-9f85-305a0b3f46a2\\\",\\n  \\\"createdUtc\\\": \\\"2020-04-11T20:38:07.5652666+00:00\\\",\\n  \\\"createdBy\\\": {\\n    \\\"userObjectId\\\": \\\"ee2572f8-4cee-4eb2-9277-177851607a9b\\\",\\n    \\\"userPuId\\\": \\\"10033FFFAF51E5BA\\\",\\n    \\\"userIdp\\\": null,\\n    \\\"userAltSecId\\\": null,\\n    \\\"userIss\\\": \\\"https://sts.windows.net/964e6f01-cb76-4800-842f-9cd7caa564c1/\\\",\\n    \\\"userTenantId\\\": \\\"964e6f01-cb76-4800-842f-9cd7caa564c1\\\",\\n    \\\"userName\\\": \\\"Anand Eswara\\\"\\n  },\\n  \\\"userId\\\": \\\"ee2572f8-4cee-4eb2-9277-177851607a9b\\\",\\n  \\\"token\\\": null,\\n  \\\"tokenExpiryTimeUtc\\\": null,\\n  \\\"error\\\": null,\\n  \\\"warnings\\\": null,\\n  \\\"revision\\\": 7,\\n  \\\"runUuid\\\": \\\"9be7af66-9ccc-44a2-9476-23748f535434\\\",\\n  \\\"parentRunUuid\\\": null,\\n  \\\"rootRunUuid\\\": \\\"9be7af66-9ccc-44a2-9476-23748f535434\\\",\\n  \\\"runId\\\": \\\"tf-cluster-multi-gpu_1586637483_41828672\\\",\\n  \\\"parentRunId\\\": null,\\n  \\\"status\\\": \\\"Running\\\",\\n  \\\"startTimeUtc\\\": \\\"2020-04-11T20:38:25.8230788+00:00\\\",\\n  \\\"endTimeUtc\\\": null,\\n  \\\"heartbeatEnabled\\\": false,\\n  \\\"options\\\": {\\n    \\\"generateDataContainerIdIfNotSpecified\\\": true\\n  },\\n  \\\"name\\\": null,\\n  \\\"dataContainerId\\\": \\\"dcid.tf-cluster-multi-gpu_1586637483_41828672\\\",\\n  \\\"description\\\": null,\\n  \\\"hidden\\\": false,\\n  \\\"runType\\\": \\\"azureml.scriptrun\\\",\\n  \\\"properties\\\": {\\n    \\\"_azureml.ComputeTargetType\\\": \\\"amlcompute\\\",\\n    \\\"ContentSnapshotId\\\": \\\"15fc5b86-e726-428a-afdf-2d643e25df4b\\\",\\n    \\\"azureml.git.repository_uri\\\": \\\"https://github.com/returncode13/AzureML.git\\\",\\n    \\\"mlflow.source.git.repoURL\\\": \\\"https://github.com/returncode13/AzureML.git\\\",\\n    \\\"azureml.git.branch\\\": \\\"dev\\\",\\n    \\\"mlflow.source.git.branch\\\": \\\"dev\\\",\\n    \\\"azureml.git.commit\\\": \\\"4cb1d1a63ee9d666f9b31647c6a1545e0c7ac969\\\",\\n    \\\"mlflow.source.git.commit\\\": \\\"4cb1d1a63ee9d666f9b31647c6a1545e0c7ac969\\\",\\n    \\\"azureml.git.dirty\\\": \\\"True\\\",\\n    \\\"ProcessInfoFile\\\": \\\"azureml-logs/process_info.json\\\",\\n    \\\"ProcessStatusFile\\\": \\\"azureml-logs/process_status.json\\\"\\n  },\\n  \\\"scriptName\\\": \\\"keras_mnist-gpu.py\\\",\\n  \\\"target\\\": \\\"sn-gpu-cls-NC12\\\",\\n  \\\"uniqueChildRunComputeTargets\\\": [],\\n  \\\"tags\\\": {\\n    \\\"_aml_system_ComputeTargetStatus\\\": \\\"{\\\\\\\"AllocationState\\\\\\\":\\\\\\\"steady\\\\\\\",\\\\\\\"PreparingNodeCount\\\\\\\":0,\\\\\\\"RunningNodeCount\\\\\\\":0,\\\\\\\"CurrentNodeCount\\\\\\\":1}\\\"\\n  },\\n  \\\"inputDatasets\\\": [],\\n  \\\"runDefinition\\\": null,\\n  \\\"createdFrom\\\": null,\\n  \\\"cancelUri\\\": \\\"https://southcentralus.experiments.azureml.net/execution/v1.0/subscriptions/c1d0a0ea-bf6e-4c1c-8b55-f1bdb0208df8/resourceGroups/awe-cirrus-rg/providers/Microsoft.MachineLearningServices/workspaces/cirrustest2/experiments/tf-cluster-multi-gpu/runId/tf-cluster-multi-gpu_1586637483_41828672/cancel\\\",\\n  \\\"completeUri\\\": null,\\n  \\\"diagnosticsUri\\\": \\\"https://southcentralus.experiments.azureml.net/execution/v1.0/subscriptions/c1d0a0ea-bf6e-4c1c-8b55-f1bdb0208df8/resourceGroups/awe-cirrus-rg/providers/Microsoft.MachineLearningServices/workspaces/cirrustest2/experiments/tf-cluster-multi-gpu/runId/tf-cluster-multi-gpu_1586637483_41828672/diagnostics\\\",\\n  \\\"computeRequest\\\": {\\n    \\\"nodeCount\\\": 1\\n  },\\n  \\\"retainForLifetimeOfWorkspace\\\": false,\\n  \\\"queueingInfo\\\": null\\n}\\n2020-04-11 20:39:12,312|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.RunClient.get-async:False|DEBUG|[STOP]\\n2020-04-11 20:39:12,313|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': '15fc5b86-e726-428a-afdf-2d643e25df4b', 'azureml.git.repository_uri': 'https://github.com/returncode13/AzureML.git', 'mlflow.source.git.repoURL': 'https://github.com/returncode13/AzureML.git', 'azureml.git.branch': 'dev', 'mlflow.source.git.branch': 'dev', 'azureml.git.commit': '4cb1d1a63ee9d666f9b31647c6a1545e0c7ac969', 'mlflow.source.git.commit': '4cb1d1a63ee9d666f9b31647c6a1545e0c7ac969', 'azureml.git.dirty': 'True', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2020-04-11 20:39:12,313|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2020-04-11 20:39:37,126|azureml.core.authentication|DEBUG|Time to expire 1814309.873371 seconds\\n2020-04-11 20:39:40,838|azureml.core._metrics|DEBUG|Converted key Loss of value 0.8612848231196404 to 0.8612848231196404.\\n\\n2020-04-11 20:39:40,838|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2020-04-11 20:39:40,839|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2020-04-11 20:39:40,839|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2020-04-11 20:39:40,839|azureml.core._metrics|DEBUG|Converted key Accuracy of value 1.525878978725359e-08 to 1.525878978725359e-08.\\n\\n2020-04-11 20:39:41,852|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2020-04-11 20:39:41,852|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2020-04-11 20:39:41,853|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Batch size 2.\\n2020-04-11 20:39:41,853|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2020-04-11 20:39:41,853|azureml._restclient.clientbase.WorkerPool|DEBUG|submitting future: _log_batch\\n2020-04-11 20:39:41,853|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2020-04-11 20:39:41,854|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[START]\\n2020-04-11 20:39:41,854|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2020-04-11 20:39:41,854|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch.0__log_batch|DEBUG|Using basic handler - no exception handling\\n2020-04-11 20:39:41,856|msrest.service_client|DEBUG|Accept header absent and forced to application/json\\n2020-04-11 20:39:41,856|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2020-04-11 20:39:41,856|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Adding task 0__log_batch to queue of approximate size: 0\\n2020-04-11 20:39:41,856|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2020-04-11 20:39:41,857|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2020-04-11 20:39:41,857|msrest.http_logger|DEBUG|Request URL: 'https://southcentralus.experiments.azureml.net/history/v1.0/subscriptions/c1d0a0ea-bf6e-4c1c-8b55-f1bdb0208df8/resourceGroups/awe-cirrus-rg/providers/Microsoft.MachineLearningServices/workspaces/cirrustest2/experiments/tf-cluster-multi-gpu/runs/tf-cluster-multi-gpu_1586637483_41828672/batch/metrics'\\n2020-04-11 20:39:41,857|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2020-04-11 20:39:41,857|msrest.http_logger|DEBUG|Request method: 'POST'\\n2020-04-11 20:39:41,857|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2020-04-11 20:39:41,857|msrest.http_logger|DEBUG|Request headers:\\n2020-04-11 20:39:41,858|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2020-04-11 20:39:41,858|msrest.http_logger|DEBUG|    'Accept': 'application/json'\\n2020-04-11 20:39:41,858|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2020-04-11 20:39:41,858|msrest.http_logger|DEBUG|    'Content-Type': 'application/json-patch+json; charset=utf-8'\\n2020-04-11 20:39:41,858|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2020-04-11 20:39:41,858|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '0d95fd42-7b81-4fc6-bf97-1f9117e3e57f'\\n2020-04-11 20:39:41,858|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2020-04-11 20:39:41,858|msrest.http_logger|DEBUG|    'request-id': '0d95fd42-7b81-4fc6-bf97-1f9117e3e57f'\\n2020-04-11 20:39:41,858|msrest.http_logger|DEBUG|    'Content-Length': '691'\\n2020-04-11 20:39:41,859|msrest.http_logger|DEBUG|    'User-Agent': 'python/3.6.9 (Linux-4.15.0-1067-azure-x86_64-with-Ubuntu-18.04-bionic) msrest/0.6.13 azureml._restclient/core.1.2.0 sdk_run'\\n2020-04-11 20:39:41,859|msrest.http_logger|DEBUG|Request body:\\n2020-04-11 20:39:41,859|msrest.http_logger|DEBUG|{\\\"values\\\": [{\\\"metricId\\\": \\\"82867fe6-f6b3-4648-be0c-a87867050567\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2020-04-11T20:39:40.838679Z\\\", \\\"name\\\": \\\"Loss\\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"Loss\\\": 0.8612848231196404}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"Loss\\\", \\\"name\\\": \\\"Loss\\\", \\\"type\\\": \\\"float\\\"}]}}, {\\\"metricId\\\": \\\"74bd0b23-b243-4dac-aec6-6670bdc5c2b7\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2020-04-11T20:39:40.839591Z\\\", \\\"name\\\": \\\"Accuracy\\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"Accuracy\\\": 1.525878978725359e-08}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"Accuracy\\\", \\\"name\\\": \\\"Accuracy\\\", \\\"type\\\": \\\"float\\\"}]}}]}\\n2020-04-11 20:39:41,859|msrest.universal_http|DEBUG|Configuring redirects: allow=True, max=30\\n2020-04-11 20:39:41,859|msrest.universal_http|DEBUG|Configuring request: timeout=100, verify=True, cert=None\\n2020-04-11 20:39:41,859|msrest.universal_http|DEBUG|Configuring proxies: ''\\n2020-04-11 20:39:41,859|msrest.universal_http|DEBUG|Evaluate proxies against ENV settings: True\\n2020-04-11 20:39:42,079|msrest.http_logger|DEBUG|Response status: 200\\n2020-04-11 20:39:42,079|msrest.http_logger|DEBUG|Response headers:\\n2020-04-11 20:39:42,079|msrest.http_logger|DEBUG|    'Date': 'Sat, 11 Apr 2020 20:39:42 GMT'\\n2020-04-11 20:39:42,080|msrest.http_logger|DEBUG|    'Content-Length': '0'\\n2020-04-11 20:39:42,080|msrest.http_logger|DEBUG|    'Connection': 'keep-alive'\\n2020-04-11 20:39:42,080|msrest.http_logger|DEBUG|    'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d'\\n2020-04-11 20:39:42,080|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '0d95fd42-7b81-4fc6-bf97-1f9117e3e57f'\\n2020-04-11 20:39:42,080|msrest.http_logger|DEBUG|    'x-ms-client-session-id': ''\\n2020-04-11 20:39:42,080|msrest.http_logger|DEBUG|    'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'\\n2020-04-11 20:39:42,080|msrest.http_logger|DEBUG|Response content:\\n2020-04-11 20:39:42,080|msrest.http_logger|DEBUG|\\n2020-04-11 20:39:42,081|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[STOP]\\n2020-04-11 20:39:55,223|azureml.core._metrics|DEBUG|Converted key Loss of value 0.2544753961265087 to 0.2544753961265087.\\n\\n2020-04-11 20:39:55,224|azureml.core._metrics|DEBUG|Converted key Accuracy of value 2.7465819840699623e-08 to 2.7465819840699623e-08.\\n\\n2020-04-11 20:39:55,882|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2020-04-11 20:39:55,883|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2020-04-11 20:39:55,883|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Batch size 2.\\n2020-04-11 20:39:55,883|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2020-04-11 20:39:55,883|azureml._restclient.clientbase.WorkerPool|DEBUG|submitting future: _log_batch\\n2020-04-11 20:39:55,883|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2020-04-11 20:39:55,884|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[START]\\n2020-04-11 20:39:55,884|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch.1__log_batch|DEBUG|Using basic handler - no exception handling\\n2020-04-11 20:39:55,884|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2020-04-11 20:39:55,886|msrest.service_client|DEBUG|Accept header absent and forced to application/json\\n2020-04-11 20:39:55,886|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Adding task 1__log_batch to queue of approximate size: 1\\n2020-04-11 20:39:55,886|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2020-04-11 20:39:55,886|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2020-04-11 20:39:55,886|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2020-04-11 20:39:55,887|msrest.http_logger|DEBUG|Request URL: 'https://southcentralus.experiments.azureml.net/history/v1.0/subscriptions/c1d0a0ea-bf6e-4c1c-8b55-f1bdb0208df8/resourceGroups/awe-cirrus-rg/providers/Microsoft.MachineLearningServices/workspaces/cirrustest2/experiments/tf-cluster-multi-gpu/runs/tf-cluster-multi-gpu_1586637483_41828672/batch/metrics'\\n2020-04-11 20:39:55,887|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2020-04-11 20:39:55,887|msrest.http_logger|DEBUG|Request method: 'POST'\\n2020-04-11 20:39:55,887|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2020-04-11 20:39:55,887|msrest.http_logger|DEBUG|Request headers:\\n2020-04-11 20:39:55,887|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2020-04-11 20:39:55,887|msrest.http_logger|DEBUG|    'Accept': 'application/json'\\n2020-04-11 20:39:55,887|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2020-04-11 20:39:55,888|msrest.http_logger|DEBUG|    'Content-Type': 'application/json-patch+json; charset=utf-8'\\n2020-04-11 20:39:55,888|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2020-04-11 20:39:55,888|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '39e54934-8496-4266-bfce-0fff3df8c479'\\n2020-04-11 20:39:55,888|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2020-04-11 20:39:55,888|msrest.http_logger|DEBUG|    'request-id': '39e54934-8496-4266-bfce-0fff3df8c479'\\n2020-04-11 20:39:55,888|msrest.http_logger|DEBUG|    'Content-Length': '692'\\n2020-04-11 20:39:55,888|msrest.http_logger|DEBUG|    'User-Agent': 'python/3.6.9 (Linux-4.15.0-1067-azure-x86_64-with-Ubuntu-18.04-bionic) msrest/0.6.13 azureml._restclient/core.1.2.0 sdk_run'\\n2020-04-11 20:39:55,889|msrest.http_logger|DEBUG|Request body:\\n2020-04-11 20:39:55,889|msrest.http_logger|DEBUG|{\\\"values\\\": [{\\\"metricId\\\": \\\"ae3e2d2f-9dcf-44cb-bf55-80aba123d3e9\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2020-04-11T20:39:55.223966Z\\\", \\\"name\\\": \\\"Loss\\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"Loss\\\": 0.2544753961265087}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"Loss\\\", \\\"name\\\": \\\"Loss\\\", \\\"type\\\": \\\"float\\\"}]}}, {\\\"metricId\\\": \\\"36da847d-cf6b-437d-a3cc-710c9a39c034\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2020-04-11T20:39:55.224201Z\\\", \\\"name\\\": \\\"Accuracy\\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"Accuracy\\\": 2.7465819840699623e-08}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"Accuracy\\\", \\\"name\\\": \\\"Accuracy\\\", \\\"type\\\": \\\"float\\\"}]}}]}\\n2020-04-11 20:39:55,889|msrest.universal_http|DEBUG|Configuring redirects: allow=True, max=30\\n2020-04-11 20:39:55,889|msrest.universal_http|DEBUG|Configuring request: timeout=100, verify=True, cert=None\\n2020-04-11 20:39:55,889|msrest.universal_http|DEBUG|Configuring proxies: ''\\n2020-04-11 20:39:55,889|msrest.universal_http|DEBUG|Evaluate proxies against ENV settings: True\\n2020-04-11 20:39:56,079|msrest.http_logger|DEBUG|Response status: 200\\n2020-04-11 20:39:56,080|msrest.http_logger|DEBUG|Response headers:\\n2020-04-11 20:39:56,080|msrest.http_logger|DEBUG|    'Date': 'Sat, 11 Apr 2020 20:39:56 GMT'\\n2020-04-11 20:39:56,080|msrest.http_logger|DEBUG|    'Content-Length': '0'\\n2020-04-11 20:39:56,080|msrest.http_logger|DEBUG|    'Connection': 'keep-alive'\\n2020-04-11 20:39:56,080|msrest.http_logger|DEBUG|    'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d'\\n2020-04-11 20:39:56,080|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '39e54934-8496-4266-bfce-0fff3df8c479'\\n2020-04-11 20:39:56,080|msrest.http_logger|DEBUG|    'x-ms-client-session-id': ''\\n2020-04-11 20:39:56,080|msrest.http_logger|DEBUG|    'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'\\n2020-04-11 20:39:56,080|msrest.http_logger|DEBUG|Response content:\\n2020-04-11 20:39:56,080|msrest.http_logger|DEBUG|\\n2020-04-11 20:39:56,082|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[STOP]\\n2020-04-11 20:40:07,126|azureml.core.authentication|DEBUG|Time to expire 1814279.87308 seconds\\n2020-04-11 20:40:09,550|azureml.core._metrics|DEBUG|Converted key Loss of value 0.16930606797337533 to 0.16930606797337533.\\n\\n2020-04-11 20:40:09,550|azureml.core._metrics|DEBUG|Converted key Accuracy of value 2.7465819840699623e-08 to 2.7465819840699623e-08.\\n\\n2020-04-11 20:40:09,894|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2020-04-11 20:40:09,894|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2020-04-11 20:40:09,895|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Batch size 2.\\n2020-04-11 20:40:09,895|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2020-04-11 20:40:09,895|azureml._restclient.clientbase.WorkerPool|DEBUG|submitting future: _log_batch\\n2020-04-11 20:40:09,895|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2020-04-11 20:40:09,895|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[START]\\n2020-04-11 20:40:09,895|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2020-04-11 20:40:09,896|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch.2__log_batch|DEBUG|Using basic handler - no exception handling\\n2020-04-11 20:40:09,897|msrest.service_client|DEBUG|Accept header absent and forced to application/json\\n2020-04-11 20:40:09,918|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2020-04-11 20:40:09,918|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Adding task 2__log_batch to queue of approximate size: 2\\n2020-04-11 20:40:09,918|msrest.http_logger|DEBUG|Request URL: 'https://southcentralus.experiments.azureml.net/history/v1.0/subscriptions/c1d0a0ea-bf6e-4c1c-8b55-f1bdb0208df8/resourceGroups/awe-cirrus-rg/providers/Microsoft.MachineLearningServices/workspaces/cirrustest2/experiments/tf-cluster-multi-gpu/runs/tf-cluster-multi-gpu_1586637483_41828672/batch/metrics'\\n2020-04-11 20:40:09,918|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2020-04-11 20:40:09,919|msrest.http_logger|DEBUG|Request method: 'POST'\\n2020-04-11 20:40:09,919|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2020-04-11 20:40:09,919|msrest.http_logger|DEBUG|Request headers:\\n2020-04-11 20:40:09,919|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2020-04-11 20:40:09,919|msrest.http_logger|DEBUG|    'Accept': 'application/json'\\n2020-04-11 20:40:09,919|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2020-04-11 20:40:09,919|msrest.http_logger|DEBUG|    'Content-Type': 'application/json-patch+json; charset=utf-8'\\n2020-04-11 20:40:09,920|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2020-04-11 20:40:09,920|msrest.http_logger|DEBUG|    'x-ms-client-request-id': 'b6dc489f-9603-48bf-9b56-9a2ea7ed545a'\\n2020-04-11 20:40:09,920|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2020-04-11 20:40:09,920|msrest.http_logger|DEBUG|    'request-id': 'b6dc489f-9603-48bf-9b56-9a2ea7ed545a'\\n2020-04-11 20:40:09,920|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2020-04-11 20:40:09,920|msrest.http_logger|DEBUG|    'Content-Length': '693'\\n2020-04-11 20:40:09,920|msrest.http_logger|DEBUG|    'User-Agent': 'python/3.6.9 (Linux-4.15.0-1067-azure-x86_64-with-Ubuntu-18.04-bionic) msrest/0.6.13 azureml._restclient/core.1.2.0 sdk_run'\\n2020-04-11 20:40:09,920|msrest.http_logger|DEBUG|Request body:\\n2020-04-11 20:40:09,921|msrest.http_logger|DEBUG|{\\\"values\\\": [{\\\"metricId\\\": \\\"2c5de456-9b50-42e3-b5a3-abdee744f4d6\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2020-04-11T20:40:09.550602Z\\\", \\\"name\\\": \\\"Loss\\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"Loss\\\": 0.16930606797337533}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"Loss\\\", \\\"name\\\": \\\"Loss\\\", \\\"type\\\": \\\"float\\\"}]}}, {\\\"metricId\\\": \\\"4e2f8367-32fb-484c-bd26-e442ba184152\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2020-04-11T20:40:09.550848Z\\\", \\\"name\\\": \\\"Accuracy\\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"Accuracy\\\": 2.7465819840699623e-08}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"Accuracy\\\", \\\"name\\\": \\\"Accuracy\\\", \\\"type\\\": \\\"float\\\"}]}}]}\\n2020-04-11 20:40:09,921|msrest.universal_http|DEBUG|Configuring redirects: allow=True, max=30\\n2020-04-11 20:40:09,921|msrest.universal_http|DEBUG|Configuring request: timeout=100, verify=True, cert=None\\n2020-04-11 20:40:09,921|msrest.universal_http|DEBUG|Configuring proxies: ''\\n2020-04-11 20:40:09,921|msrest.universal_http|DEBUG|Evaluate proxies against ENV settings: True\\n2020-04-11 20:40:10,047|msrest.http_logger|DEBUG|Response status: 200\\n2020-04-11 20:40:10,047|msrest.http_logger|DEBUG|Response headers:\\n2020-04-11 20:40:10,047|msrest.http_logger|DEBUG|    'Date': 'Sat, 11 Apr 2020 20:40:10 GMT'\\n2020-04-11 20:40:10,047|msrest.http_logger|DEBUG|    'Content-Length': '0'\\n2020-04-11 20:40:10,047|msrest.http_logger|DEBUG|    'Connection': 'keep-alive'\\n2020-04-11 20:40:10,047|msrest.http_logger|DEBUG|    'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d'\\n2020-04-11 20:40:10,047|msrest.http_logger|DEBUG|    'x-ms-client-request-id': 'b6dc489f-9603-48bf-9b56-9a2ea7ed545a'\\n2020-04-11 20:40:10,047|msrest.http_logger|DEBUG|    'x-ms-client-session-id': ''\\n2020-04-11 20:40:10,047|msrest.http_logger|DEBUG|    'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'\\n2020-04-11 20:40:10,047|msrest.http_logger|DEBUG|Response content:\\n2020-04-11 20:40:10,048|msrest.http_logger|DEBUG|\\n2020-04-11 20:40:10,049|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[STOP]\\n2020-04-11 20:40:22,926|azureml.core._metrics|DEBUG|Converted key Loss of value 0.13404045790433883 to 0.13404045790433883.\\n\\n2020-04-11 20:40:22,926|azureml.core._metrics|DEBUG|Converted key Accuracy of value 2.7465819840699623e-08 to 2.7465819840699623e-08.\\n\\n2020-04-11 20:40:23,926|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2020-04-11 20:40:23,926|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2020-04-11 20:40:23,927|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Batch size 2.\\n2020-04-11 20:40:23,927|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2020-04-11 20:40:23,927|azureml._restclient.clientbase.WorkerPool|DEBUG|submitting future: _log_batch\\n2020-04-11 20:40:23,927|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2020-04-11 20:40:23,927|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[START]\\n2020-04-11 20:40:23,928|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2020-04-11 20:40:23,928|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch.3__log_batch|DEBUG|Using basic handler - no exception handling\\n2020-04-11 20:40:23,929|msrest.service_client|DEBUG|Accept header absent and forced to application/json\\n2020-04-11 20:40:23,929|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2020-04-11 20:40:23,929|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Adding task 3__log_batch to queue of approximate size: 3\\n2020-04-11 20:40:23,930|msrest.http_logger|DEBUG|Request URL: 'https://southcentralus.experiments.azureml.net/history/v1.0/subscriptions/c1d0a0ea-bf6e-4c1c-8b55-f1bdb0208df8/resourceGroups/awe-cirrus-rg/providers/Microsoft.MachineLearningServices/workspaces/cirrustest2/experiments/tf-cluster-multi-gpu/runs/tf-cluster-multi-gpu_1586637483_41828672/batch/metrics'\\n2020-04-11 20:40:23,930|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2020-04-11 20:40:23,930|msrest.http_logger|DEBUG|Request method: 'POST'\\n2020-04-11 20:40:23,930|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2020-04-11 20:40:23,930|msrest.http_logger|DEBUG|Request headers:\\n2020-04-11 20:40:23,930|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2020-04-11 20:40:23,930|msrest.http_logger|DEBUG|    'Accept': 'application/json'\\n2020-04-11 20:40:23,931|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2020-04-11 20:40:23,931|msrest.http_logger|DEBUG|    'Content-Type': 'application/json-patch+json; charset=utf-8'\\n2020-04-11 20:40:23,931|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2020-04-11 20:40:23,931|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '4bd0f303-b9b0-42ed-9735-ec7416d0adb7'\\n2020-04-11 20:40:23,931|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2020-04-11 20:40:23,931|msrest.http_logger|DEBUG|    'request-id': '4bd0f303-b9b0-42ed-9735-ec7416d0adb7'\\n2020-04-11 20:40:23,931|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2020-04-11 20:40:23,931|msrest.http_logger|DEBUG|    'Content-Length': '693'\\n2020-04-11 20:40:23,932|msrest.http_logger|DEBUG|    'User-Agent': 'python/3.6.9 (Linux-4.15.0-1067-azure-x86_64-with-Ubuntu-18.04-bionic) msrest/0.6.13 azureml._restclient/core.1.2.0 sdk_run'\\n2020-04-11 20:40:23,932|msrest.http_logger|DEBUG|Request body:\\n2020-04-11 20:40:23,932|msrest.http_logger|DEBUG|{\\\"values\\\": [{\\\"metricId\\\": \\\"edab5f0c-2404-4c55-a9b7-b53dd0916f44\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2020-04-11T20:40:22.926851Z\\\", \\\"name\\\": \\\"Loss\\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"Loss\\\": 0.13404045790433883}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"Loss\\\", \\\"name\\\": \\\"Loss\\\", \\\"type\\\": \\\"float\\\"}]}}, {\\\"metricId\\\": \\\"31223362-7445-4a0a-b8c7-1e1f0c692e36\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2020-04-11T20:40:22.927094Z\\\", \\\"name\\\": \\\"Accuracy\\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"Accuracy\\\": 2.7465819840699623e-08}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"Accuracy\\\", \\\"name\\\": \\\"Accuracy\\\", \\\"type\\\": \\\"float\\\"}]}}]}\\n2020-04-11 20:40:23,932|msrest.universal_http|DEBUG|Configuring redirects: allow=True, max=30\\n2020-04-11 20:40:23,932|msrest.universal_http|DEBUG|Configuring request: timeout=100, verify=True, cert=None\\n2020-04-11 20:40:23,932|msrest.universal_http|DEBUG|Configuring proxies: ''\\n2020-04-11 20:40:23,932|msrest.universal_http|DEBUG|Evaluate proxies against ENV settings: True\\n2020-04-11 20:40:24,158|msrest.http_logger|DEBUG|Response status: 200\\n2020-04-11 20:40:24,159|msrest.http_logger|DEBUG|Response headers:\\n2020-04-11 20:40:24,159|msrest.http_logger|DEBUG|    'Date': 'Sat, 11 Apr 2020 20:40:24 GMT'\\n2020-04-11 20:40:24,159|msrest.http_logger|DEBUG|    'Content-Length': '0'\\n2020-04-11 20:40:24,159|msrest.http_logger|DEBUG|    'Connection': 'keep-alive'\\n2020-04-11 20:40:24,159|msrest.http_logger|DEBUG|    'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d'\\n2020-04-11 20:40:24,159|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '4bd0f303-b9b0-42ed-9735-ec7416d0adb7'\\n2020-04-11 20:40:24,159|msrest.http_logger|DEBUG|    'x-ms-client-session-id': ''\\n2020-04-11 20:40:24,159|msrest.http_logger|DEBUG|    'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'\\n2020-04-11 20:40:24,159|msrest.http_logger|DEBUG|Response content:\\n2020-04-11 20:40:24,160|msrest.http_logger|DEBUG|\\n2020-04-11 20:40:24,161|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[STOP]\\n2020-04-11 20:40:37,129|azureml.core.authentication|DEBUG|Time to expire 1814249.870789 seconds\\n2020-04-11 20:40:37,370|azureml.core._metrics|DEBUG|Converted key Loss of value 0.11144404038786888 to 0.11144404038786888.\\n\\n2020-04-11 20:40:37,371|azureml.core._metrics|DEBUG|Converted key Accuracy of value 2.7465819840699623e-08 to 2.7465819840699623e-08.\\n\\n2020-04-11 20:40:37,935|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2020-04-11 20:40:37,936|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2020-04-11 20:40:37,936|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Batch size 2.\\n2020-04-11 20:40:37,936|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2020-04-11 20:40:37,936|azureml._restclient.clientbase.WorkerPool|DEBUG|submitting future: _log_batch\\n2020-04-11 20:40:37,936|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2020-04-11 20:40:37,937|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[START]\\n2020-04-11 20:40:37,937|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2020-04-11 20:40:37,937|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch.4__log_batch|DEBUG|Using basic handler - no exception handling\\n2020-04-11 20:40:37,938|msrest.service_client|DEBUG|Accept header absent and forced to application/json\\n2020-04-11 20:40:37,938|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2020-04-11 20:40:37,939|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Adding task 4__log_batch to queue of approximate size: 4\\n2020-04-11 20:40:37,939|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2020-04-11 20:40:37,939|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2020-04-11 20:40:37,939|msrest.http_logger|DEBUG|Request URL: 'https://southcentralus.experiments.azureml.net/history/v1.0/subscriptions/c1d0a0ea-bf6e-4c1c-8b55-f1bdb0208df8/resourceGroups/awe-cirrus-rg/providers/Microsoft.MachineLearningServices/workspaces/cirrustest2/experiments/tf-cluster-multi-gpu/runs/tf-cluster-multi-gpu_1586637483_41828672/batch/metrics'\\n2020-04-11 20:40:37,940|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2020-04-11 20:40:37,940|msrest.http_logger|DEBUG|Request method: 'POST'\\n2020-04-11 20:40:37,940|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2020-04-11 20:40:37,940|msrest.http_logger|DEBUG|Request headers:\\n2020-04-11 20:40:37,940|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2020-04-11 20:40:37,940|msrest.http_logger|DEBUG|    'Accept': 'application/json'\\n2020-04-11 20:40:37,940|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2020-04-11 20:40:37,940|msrest.http_logger|DEBUG|    'Content-Type': 'application/json-patch+json; charset=utf-8'\\n2020-04-11 20:40:37,940|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2020-04-11 20:40:37,940|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '41574030-d7cd-4303-b5ce-9d564706ba70'\\n2020-04-11 20:40:37,941|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2020-04-11 20:40:37,941|msrest.http_logger|DEBUG|    'request-id': '41574030-d7cd-4303-b5ce-9d564706ba70'\\n2020-04-11 20:40:37,941|msrest.http_logger|DEBUG|    'Content-Length': '693'\\n2020-04-11 20:40:37,941|msrest.http_logger|DEBUG|    'User-Agent': 'python/3.6.9 (Linux-4.15.0-1067-azure-x86_64-with-Ubuntu-18.04-bionic) msrest/0.6.13 azureml._restclient/core.1.2.0 sdk_run'\\n2020-04-11 20:40:37,941|msrest.http_logger|DEBUG|Request body:\\n2020-04-11 20:40:37,941|msrest.http_logger|DEBUG|{\\\"values\\\": [{\\\"metricId\\\": \\\"f80bc8ab-d917-458b-a128-fcd9c501205a\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2020-04-11T20:40:37.371112Z\\\", \\\"name\\\": \\\"Loss\\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"Loss\\\": 0.11144404038786888}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"Loss\\\", \\\"name\\\": \\\"Loss\\\", \\\"type\\\": \\\"float\\\"}]}}, {\\\"metricId\\\": \\\"34523763-6294-47a7-9c5d-982ac6c0ab06\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2020-04-11T20:40:37.371366Z\\\", \\\"name\\\": \\\"Accuracy\\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"Accuracy\\\": 2.7465819840699623e-08}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"Accuracy\\\", \\\"name\\\": \\\"Accuracy\\\", \\\"type\\\": \\\"float\\\"}]}}]}\\n2020-04-11 20:40:37,941|msrest.universal_http|DEBUG|Configuring redirects: allow=True, max=30\\n2020-04-11 20:40:37,941|msrest.universal_http|DEBUG|Configuring request: timeout=100, verify=True, cert=None\\n2020-04-11 20:40:37,941|msrest.universal_http|DEBUG|Configuring proxies: ''\\n2020-04-11 20:40:37,941|msrest.universal_http|DEBUG|Evaluate proxies against ENV settings: True\\n2020-04-11 20:40:38,064|msrest.http_logger|DEBUG|Response status: 200\\n2020-04-11 20:40:38,065|msrest.http_logger|DEBUG|Response headers:\\n2020-04-11 20:40:38,065|msrest.http_logger|DEBUG|    'Date': 'Sat, 11 Apr 2020 20:40:38 GMT'\\n2020-04-11 20:40:38,065|msrest.http_logger|DEBUG|    'Content-Length': '0'\\n2020-04-11 20:40:38,065|msrest.http_logger|DEBUG|    'Connection': 'keep-alive'\\n2020-04-11 20:40:38,065|msrest.http_logger|DEBUG|    'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d'\\n2020-04-11 20:40:38,065|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '41574030-d7cd-4303-b5ce-9d564706ba70'\\n2020-04-11 20:40:38,065|msrest.http_logger|DEBUG|    'x-ms-client-session-id': ''\\n2020-04-11 20:40:38,065|msrest.http_logger|DEBUG|    'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'\\n2020-04-11 20:40:38,065|msrest.http_logger|DEBUG|Response content:\\n2020-04-11 20:40:38,065|msrest.http_logger|DEBUG|\\n2020-04-11 20:40:38,067|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[STOP]\\n2020-04-11 20:40:51,407|azureml.core._metrics|DEBUG|Converted key Loss of value 0.09654842272400856 to 0.09654842272400856.\\n\\n2020-04-11 20:40:51,407|azureml.core._metrics|DEBUG|Converted key Accuracy of value 2.7465819840699623e-08 to 2.7465819840699623e-08.\\n\\n2020-04-11 20:40:51,958|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2020-04-11 20:40:51,958|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2020-04-11 20:40:51,958|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Batch size 2.\\n2020-04-11 20:40:51,958|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2020-04-11 20:40:51,958|azureml._restclient.clientbase.WorkerPool|DEBUG|submitting future: _log_batch\\n2020-04-11 20:40:51,959|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2020-04-11 20:40:51,959|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[START]\\n2020-04-11 20:40:51,959|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2020-04-11 20:40:51,959|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch.5__log_batch|DEBUG|Using basic handler - no exception handling\\n2020-04-11 20:40:51,960|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2020-04-11 20:40:51,961|msrest.service_client|DEBUG|Accept header absent and forced to application/json\\n2020-04-11 20:40:51,961|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Adding task 5__log_batch to queue of approximate size: 5\\n2020-04-11 20:40:51,961|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2020-04-11 20:40:51,962|msrest.http_logger|DEBUG|Request URL: 'https://southcentralus.experiments.azureml.net/history/v1.0/subscriptions/c1d0a0ea-bf6e-4c1c-8b55-f1bdb0208df8/resourceGroups/awe-cirrus-rg/providers/Microsoft.MachineLearningServices/workspaces/cirrustest2/experiments/tf-cluster-multi-gpu/runs/tf-cluster-multi-gpu_1586637483_41828672/batch/metrics'\\n2020-04-11 20:40:51,962|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2020-04-11 20:40:51,962|msrest.http_logger|DEBUG|Request method: 'POST'\\n2020-04-11 20:40:51,962|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2020-04-11 20:40:51,962|msrest.http_logger|DEBUG|Request headers:\\n2020-04-11 20:40:51,962|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2020-04-11 20:40:51,962|msrest.http_logger|DEBUG|    'Accept': 'application/json'\\n2020-04-11 20:40:51,963|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2020-04-11 20:40:51,963|msrest.http_logger|DEBUG|    'Content-Type': 'application/json-patch+json; charset=utf-8'\\n2020-04-11 20:40:51,963|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2020-04-11 20:40:51,963|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '95eb9f0a-621c-4e70-8606-e354bcb881ba'\\n2020-04-11 20:40:51,963|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2020-04-11 20:40:51,963|msrest.http_logger|DEBUG|    'request-id': '95eb9f0a-621c-4e70-8606-e354bcb881ba'\\n2020-04-11 20:40:51,963|msrest.http_logger|DEBUG|    'Content-Length': '693'\\n2020-04-11 20:40:51,963|msrest.http_logger|DEBUG|    'User-Agent': 'python/3.6.9 (Linux-4.15.0-1067-azure-x86_64-with-Ubuntu-18.04-bionic) msrest/0.6.13 azureml._restclient/core.1.2.0 sdk_run'\\n2020-04-11 20:40:51,963|msrest.http_logger|DEBUG|Request body:\\n2020-04-11 20:40:51,963|msrest.http_logger|DEBUG|{\\\"values\\\": [{\\\"metricId\\\": \\\"16b44a04-1ebf-4d7d-8a8f-1d3f61a08088\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2020-04-11T20:40:51.407509Z\\\", \\\"name\\\": \\\"Loss\\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"Loss\\\": 0.09654842272400856}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"Loss\\\", \\\"name\\\": \\\"Loss\\\", \\\"type\\\": \\\"float\\\"}]}}, {\\\"metricId\\\": \\\"f99e6a5f-0a9a-4c30-81a6-a840497ebffe\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2020-04-11T20:40:51.407759Z\\\", \\\"name\\\": \\\"Accuracy\\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"Accuracy\\\": 2.7465819840699623e-08}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"Accuracy\\\", \\\"name\\\": \\\"Accuracy\\\", \\\"type\\\": \\\"float\\\"}]}}]}\\n2020-04-11 20:40:51,964|msrest.universal_http|DEBUG|Configuring redirects: allow=True, max=30\\n2020-04-11 20:40:51,964|msrest.universal_http|DEBUG|Configuring request: timeout=100, verify=True, cert=None\\n2020-04-11 20:40:51,964|msrest.universal_http|DEBUG|Configuring proxies: ''\\n2020-04-11 20:40:51,964|msrest.universal_http|DEBUG|Evaluate proxies against ENV settings: True\\n2020-04-11 20:40:52,087|msrest.http_logger|DEBUG|Response status: 200\\n2020-04-11 20:40:52,087|msrest.http_logger|DEBUG|Response headers:\\n2020-04-11 20:40:52,088|msrest.http_logger|DEBUG|    'Date': 'Sat, 11 Apr 2020 20:40:52 GMT'\\n2020-04-11 20:40:52,088|msrest.http_logger|DEBUG|    'Content-Length': '0'\\n2020-04-11 20:40:52,088|msrest.http_logger|DEBUG|    'Connection': 'keep-alive'\\n2020-04-11 20:40:52,088|msrest.http_logger|DEBUG|    'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d'\\n2020-04-11 20:40:52,088|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '95eb9f0a-621c-4e70-8606-e354bcb881ba'\\n2020-04-11 20:40:52,088|msrest.http_logger|DEBUG|    'x-ms-client-session-id': ''\\n2020-04-11 20:40:52,088|msrest.http_logger|DEBUG|    'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'\\n2020-04-11 20:40:52,088|msrest.http_logger|DEBUG|Response content:\\n2020-04-11 20:40:52,088|msrest.http_logger|DEBUG|\\n2020-04-11 20:40:52,090|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[STOP]\\n2020-04-11 20:41:04,990|azureml.core._metrics|DEBUG|Converted key Loss of value 0.08667242176830768 to 0.08667242176830768.\\n\\n2020-04-11 20:41:04,990|azureml.core._metrics|DEBUG|Converted key Accuracy of value 2.7465819840699623e-08 to 2.7465819840699623e-08.\\n\\n2020-04-11 20:41:05,969|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2020-04-11 20:41:05,969|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2020-04-11 20:41:05,970|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Batch size 2.\\n2020-04-11 20:41:05,970|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2020-04-11 20:41:05,970|azureml._restclient.clientbase.WorkerPool|DEBUG|submitting future: _log_batch\\n2020-04-11 20:41:05,970|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2020-04-11 20:41:05,970|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[START]\\n2020-04-11 20:41:05,970|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2020-04-11 20:41:05,971|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch.6__log_batch|DEBUG|Using basic handler - no exception handling\\n2020-04-11 20:41:05,972|msrest.service_client|DEBUG|Accept header absent and forced to application/json\\n2020-04-11 20:41:05,972|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2020-04-11 20:41:05,972|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Adding task 6__log_batch to queue of approximate size: 6\\n2020-04-11 20:41:05,972|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2020-04-11 20:41:05,972|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2020-04-11 20:41:05,973|msrest.http_logger|DEBUG|Request URL: 'https://southcentralus.experiments.azureml.net/history/v1.0/subscriptions/c1d0a0ea-bf6e-4c1c-8b55-f1bdb0208df8/resourceGroups/awe-cirrus-rg/providers/Microsoft.MachineLearningServices/workspaces/cirrustest2/experiments/tf-cluster-multi-gpu/runs/tf-cluster-multi-gpu_1586637483_41828672/batch/metrics'\\n2020-04-11 20:41:05,973|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2020-04-11 20:41:05,973|msrest.http_logger|DEBUG|Request method: 'POST'\\n2020-04-11 20:41:05,973|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2020-04-11 20:41:05,973|msrest.http_logger|DEBUG|Request headers:\\n2020-04-11 20:41:05,973|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2020-04-11 20:41:05,973|msrest.http_logger|DEBUG|    'Accept': 'application/json'\\n2020-04-11 20:41:05,974|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2020-04-11 20:41:05,974|msrest.http_logger|DEBUG|    'Content-Type': 'application/json-patch+json; charset=utf-8'\\n2020-04-11 20:41:05,974|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2020-04-11 20:41:05,974|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '63137ce4-7201-4567-9029-5bf08c6cde18'\\n2020-04-11 20:41:05,974|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2020-04-11 20:41:05,974|msrest.http_logger|DEBUG|    'request-id': '63137ce4-7201-4567-9029-5bf08c6cde18'\\n2020-04-11 20:41:05,974|msrest.http_logger|DEBUG|    'Content-Length': '692'\\n2020-04-11 20:41:05,974|msrest.http_logger|DEBUG|    'User-Agent': 'python/3.6.9 (Linux-4.15.0-1067-azure-x86_64-with-Ubuntu-18.04-bionic) msrest/0.6.13 azureml._restclient/core.1.2.0 sdk_run'\\n2020-04-11 20:41:05,974|msrest.http_logger|DEBUG|Request body:\\n2020-04-11 20:41:05,974|msrest.http_logger|DEBUG|{\\\"values\\\": [{\\\"metricId\\\": \\\"f252432f-f2f5-43ce-83d2-8a608a59749b\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2020-04-11T20:41:04.990705Z\\\", \\\"name\\\": \\\"Loss\\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"Loss\\\": 0.08667242176830768}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"Loss\\\", \\\"name\\\": \\\"Loss\\\", \\\"type\\\": \\\"float\\\"}]}}, {\\\"metricId\\\": \\\"1ddd86af-48e3-4f15-806f-cb7ed3a8f1be\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2020-04-11T20:41:04.99094Z\\\", \\\"name\\\": \\\"Accuracy\\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"Accuracy\\\": 2.7465819840699623e-08}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"Accuracy\\\", \\\"name\\\": \\\"Accuracy\\\", \\\"type\\\": \\\"float\\\"}]}}]}\\n2020-04-11 20:41:05,975|msrest.universal_http|DEBUG|Configuring redirects: allow=True, max=30\\n2020-04-11 20:41:05,975|msrest.universal_http|DEBUG|Configuring request: timeout=100, verify=True, cert=None\\n2020-04-11 20:41:05,975|msrest.universal_http|DEBUG|Configuring proxies: ''\\n2020-04-11 20:41:05,975|msrest.universal_http|DEBUG|Evaluate proxies against ENV settings: True\\n2020-04-11 20:41:06,111|msrest.http_logger|DEBUG|Response status: 200\\n2020-04-11 20:41:06,111|msrest.http_logger|DEBUG|Response headers:\\n2020-04-11 20:41:06,112|msrest.http_logger|DEBUG|    'Date': 'Sat, 11 Apr 2020 20:41:06 GMT'\\n2020-04-11 20:41:06,112|msrest.http_logger|DEBUG|    'Content-Length': '0'\\n2020-04-11 20:41:06,112|msrest.http_logger|DEBUG|    'Connection': 'keep-alive'\\n2020-04-11 20:41:06,112|msrest.http_logger|DEBUG|    'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d'\\n2020-04-11 20:41:06,112|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '63137ce4-7201-4567-9029-5bf08c6cde18'\\n2020-04-11 20:41:06,112|msrest.http_logger|DEBUG|    'x-ms-client-session-id': ''\\n2020-04-11 20:41:06,112|msrest.http_logger|DEBUG|    'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'\\n2020-04-11 20:41:06,112|msrest.http_logger|DEBUG|Response content:\\n2020-04-11 20:41:06,112|msrest.http_logger|DEBUG|\\n2020-04-11 20:41:06,113|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[STOP]\\n2020-04-11 20:41:07,129|azureml.core.authentication|DEBUG|Time to expire 1814219.870433 seconds\\n2020-04-11 20:41:19,227|azureml.core._metrics|DEBUG|Converted key Loss of value 0.07974897757172585 to 0.07974897757172585.\\n\\n2020-04-11 20:41:19,228|azureml.core._metrics|DEBUG|Converted key Accuracy of value 2.4414061883248905e-08 to 2.4414061883248905e-08.\\n\\n2020-04-11 20:41:19,997|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2020-04-11 20:41:19,997|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2020-04-11 20:41:19,997|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Batch size 2.\\n2020-04-11 20:41:19,998|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2020-04-11 20:41:19,998|azureml._restclient.clientbase.WorkerPool|DEBUG|submitting future: _log_batch\\n2020-04-11 20:41:19,998|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2020-04-11 20:41:19,998|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[START]\\n2020-04-11 20:41:19,998|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2020-04-11 20:41:19,998|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch.7__log_batch|DEBUG|Using basic handler - no exception handling\\n2020-04-11 20:41:20,000|msrest.service_client|DEBUG|Accept header absent and forced to application/json\\n2020-04-11 20:41:20,000|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2020-04-11 20:41:20,000|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Adding task 7__log_batch to queue of approximate size: 7\\n2020-04-11 20:41:20,000|msrest.http_logger|DEBUG|Request URL: 'https://southcentralus.experiments.azureml.net/history/v1.0/subscriptions/c1d0a0ea-bf6e-4c1c-8b55-f1bdb0208df8/resourceGroups/awe-cirrus-rg/providers/Microsoft.MachineLearningServices/workspaces/cirrustest2/experiments/tf-cluster-multi-gpu/runs/tf-cluster-multi-gpu_1586637483_41828672/batch/metrics'\\n2020-04-11 20:41:20,000|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2020-04-11 20:41:20,001|msrest.http_logger|DEBUG|Request method: 'POST'\\n2020-04-11 20:41:20,001|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2020-04-11 20:41:20,001|msrest.http_logger|DEBUG|Request headers:\\n2020-04-11 20:41:20,001|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2020-04-11 20:41:20,001|msrest.http_logger|DEBUG|    'Accept': 'application/json'\\n2020-04-11 20:41:20,001|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2020-04-11 20:41:20,001|msrest.http_logger|DEBUG|    'Content-Type': 'application/json-patch+json; charset=utf-8'\\n2020-04-11 20:41:20,002|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2020-04-11 20:41:20,002|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '75980f25-442d-4c26-a721-bebecd960be4'\\n2020-04-11 20:41:20,002|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2020-04-11 20:41:20,002|msrest.http_logger|DEBUG|    'request-id': '75980f25-442d-4c26-a721-bebecd960be4'\\n2020-04-11 20:41:20,002|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2020-04-11 20:41:20,002|msrest.http_logger|DEBUG|    'Content-Length': '693'\\n2020-04-11 20:41:20,002|msrest.http_logger|DEBUG|    'User-Agent': 'python/3.6.9 (Linux-4.15.0-1067-azure-x86_64-with-Ubuntu-18.04-bionic) msrest/0.6.13 azureml._restclient/core.1.2.0 sdk_run'\\n2020-04-11 20:41:20,002|msrest.http_logger|DEBUG|Request body:\\n2020-04-11 20:41:20,002|msrest.http_logger|DEBUG|{\\\"values\\\": [{\\\"metricId\\\": \\\"91c4a48f-eb00-43e6-ae1a-591c0200f344\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2020-04-11T20:41:19.227971Z\\\", \\\"name\\\": \\\"Loss\\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"Loss\\\": 0.07974897757172585}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"Loss\\\", \\\"name\\\": \\\"Loss\\\", \\\"type\\\": \\\"float\\\"}]}}, {\\\"metricId\\\": \\\"e5495112-227a-429d-a1d4-a7bab20b771a\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2020-04-11T20:41:19.228228Z\\\", \\\"name\\\": \\\"Accuracy\\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"Accuracy\\\": 2.4414061883248905e-08}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"Accuracy\\\", \\\"name\\\": \\\"Accuracy\\\", \\\"type\\\": \\\"float\\\"}]}}]}\\n2020-04-11 20:41:20,003|msrest.universal_http|DEBUG|Configuring redirects: allow=True, max=30\\n2020-04-11 20:41:20,003|msrest.universal_http|DEBUG|Configuring request: timeout=100, verify=True, cert=None\\n2020-04-11 20:41:20,003|msrest.universal_http|DEBUG|Configuring proxies: ''\\n2020-04-11 20:41:20,003|msrest.universal_http|DEBUG|Evaluate proxies against ENV settings: True\\n2020-04-11 20:41:20,125|msrest.http_logger|DEBUG|Response status: 200\\n2020-04-11 20:41:20,125|msrest.http_logger|DEBUG|Response headers:\\n2020-04-11 20:41:20,125|msrest.http_logger|DEBUG|    'Date': 'Sat, 11 Apr 2020 20:41:20 GMT'\\n2020-04-11 20:41:20,125|msrest.http_logger|DEBUG|    'Content-Length': '0'\\n2020-04-11 20:41:20,125|msrest.http_logger|DEBUG|    'Connection': 'keep-alive'\\n2020-04-11 20:41:20,125|msrest.http_logger|DEBUG|    'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d'\\n2020-04-11 20:41:20,125|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '75980f25-442d-4c26-a721-bebecd960be4'\\n2020-04-11 20:41:20,126|msrest.http_logger|DEBUG|    'x-ms-client-session-id': ''\\n2020-04-11 20:41:20,126|msrest.http_logger|DEBUG|    'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'\\n2020-04-11 20:41:20,126|msrest.http_logger|DEBUG|Response content:\\n2020-04-11 20:41:20,126|msrest.http_logger|DEBUG|\\n2020-04-11 20:41:20,127|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[STOP]\\n2020-04-11 20:41:33,140|azureml.core._metrics|DEBUG|Converted key Loss of value 0.07460214287042617 to 0.07460214287042617.\\n\\n2020-04-11 20:41:33,141|azureml.core._metrics|DEBUG|Converted key Accuracy of value 2.7465819840699623e-08 to 2.7465819840699623e-08.\\n\\n2020-04-11 20:41:34,007|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2020-04-11 20:41:34,007|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2020-04-11 20:41:34,007|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Batch size 2.\\n2020-04-11 20:41:34,008|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2020-04-11 20:41:34,008|azureml._restclient.clientbase.WorkerPool|DEBUG|submitting future: _log_batch\\n2020-04-11 20:41:34,008|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2020-04-11 20:41:34,008|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[START]\\n2020-04-11 20:41:34,008|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2020-04-11 20:41:34,008|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch.8__log_batch|DEBUG|Using basic handler - no exception handling\\n2020-04-11 20:41:34,010|msrest.service_client|DEBUG|Accept header absent and forced to application/json\\n2020-04-11 20:41:34,010|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2020-04-11 20:41:34,010|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Adding task 8__log_batch to queue of approximate size: 8\\n2020-04-11 20:41:34,011|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2020-04-11 20:41:34,011|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2020-04-11 20:41:34,011|msrest.http_logger|DEBUG|Request URL: 'https://southcentralus.experiments.azureml.net/history/v1.0/subscriptions/c1d0a0ea-bf6e-4c1c-8b55-f1bdb0208df8/resourceGroups/awe-cirrus-rg/providers/Microsoft.MachineLearningServices/workspaces/cirrustest2/experiments/tf-cluster-multi-gpu/runs/tf-cluster-multi-gpu_1586637483_41828672/batch/metrics'\\n2020-04-11 20:41:34,011|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2020-04-11 20:41:34,011|msrest.http_logger|DEBUG|Request method: 'POST'\\n2020-04-11 20:41:34,012|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2020-04-11 20:41:34,012|msrest.http_logger|DEBUG|Request headers:\\n2020-04-11 20:41:34,012|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2020-04-11 20:41:34,012|msrest.http_logger|DEBUG|    'Accept': 'application/json'\\n2020-04-11 20:41:34,012|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2020-04-11 20:41:34,013|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2020-04-11 20:41:34,013|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2020-04-11 20:41:34,012|msrest.http_logger|DEBUG|    'Content-Type': 'application/json-patch+json; charset=utf-8'\\n2020-04-11 20:41:34,013|msrest.http_logger|DEBUG|    'x-ms-client-request-id': 'bc12d470-7cba-4adf-8ba4-cacc5b1f8543'\\n2020-04-11 20:41:34,013|msrest.http_logger|DEBUG|    'request-id': 'bc12d470-7cba-4adf-8ba4-cacc5b1f8543'\\n2020-04-11 20:41:34,013|msrest.http_logger|DEBUG|    'Content-Length': '693'\\n2020-04-11 20:41:34,013|msrest.http_logger|DEBUG|    'User-Agent': 'python/3.6.9 (Linux-4.15.0-1067-azure-x86_64-with-Ubuntu-18.04-bionic) msrest/0.6.13 azureml._restclient/core.1.2.0 sdk_run'\\n2020-04-11 20:41:34,014|msrest.http_logger|DEBUG|Request body:\\n2020-04-11 20:41:34,014|msrest.http_logger|DEBUG|{\\\"values\\\": [{\\\"metricId\\\": \\\"53400caf-e3af-42fd-930a-bd250ba00357\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2020-04-11T20:41:33.140894Z\\\", \\\"name\\\": \\\"Loss\\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"Loss\\\": 0.07460214287042617}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"Loss\\\", \\\"name\\\": \\\"Loss\\\", \\\"type\\\": \\\"float\\\"}]}}, {\\\"metricId\\\": \\\"6e31f172-26d5-4055-87c0-49b28540feb5\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2020-04-11T20:41:33.141164Z\\\", \\\"name\\\": \\\"Accuracy\\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"Accuracy\\\": 2.7465819840699623e-08}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"Accuracy\\\", \\\"name\\\": \\\"Accuracy\\\", \\\"type\\\": \\\"float\\\"}]}}]}\\n2020-04-11 20:41:34,014|msrest.universal_http|DEBUG|Configuring redirects: allow=True, max=30\\n2020-04-11 20:41:34,014|msrest.universal_http|DEBUG|Configuring request: timeout=100, verify=True, cert=None\\n2020-04-11 20:41:34,034|msrest.universal_http|DEBUG|Configuring proxies: ''\\n2020-04-11 20:41:34,034|msrest.universal_http|DEBUG|Evaluate proxies against ENV settings: True\\n2020-04-11 20:41:34,136|msrest.http_logger|DEBUG|Response status: 200\\n2020-04-11 20:41:34,136|msrest.http_logger|DEBUG|Response headers:\\n2020-04-11 20:41:34,137|msrest.http_logger|DEBUG|    'Date': 'Sat, 11 Apr 2020 20:41:34 GMT'\\n2020-04-11 20:41:34,137|msrest.http_logger|DEBUG|    'Content-Length': '0'\\n2020-04-11 20:41:34,137|msrest.http_logger|DEBUG|    'Connection': 'keep-alive'\\n2020-04-11 20:41:34,137|msrest.http_logger|DEBUG|    'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d'\\n2020-04-11 20:41:34,137|msrest.http_logger|DEBUG|    'x-ms-client-request-id': 'bc12d470-7cba-4adf-8ba4-cacc5b1f8543'\\n2020-04-11 20:41:34,137|msrest.http_logger|DEBUG|    'x-ms-client-session-id': ''\\n2020-04-11 20:41:34,137|msrest.http_logger|DEBUG|    'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'\\n2020-04-11 20:41:34,137|msrest.http_logger|DEBUG|Response content:\\n2020-04-11 20:41:34,137|msrest.http_logger|DEBUG|\\n2020-04-11 20:41:34,139|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[STOP]\\n2020-04-11 20:41:37,130|azureml.core.authentication|DEBUG|Time to expire 1814189.869954 seconds\\n2020-04-11 20:41:46,107|azureml.core._metrics|DEBUG|Converted key Loss of value 0.07064146853983402 to 0.07064146853983402.\\n\\n2020-04-11 20:41:46,107|azureml.core._metrics|DEBUG|Converted key Accuracy of value 2.4414061883248905e-08 to 2.4414061883248905e-08.\\n\\n2020-04-11 20:41:47,043|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2020-04-11 20:41:47,044|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2020-04-11 20:41:47,044|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Batch size 2.\\n2020-04-11 20:41:47,044|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2020-04-11 20:41:47,044|azureml._restclient.clientbase.WorkerPool|DEBUG|submitting future: _log_batch\\n2020-04-11 20:41:47,045|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2020-04-11 20:41:47,045|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[START]\\n2020-04-11 20:41:47,045|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2020-04-11 20:41:47,045|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch.9__log_batch|DEBUG|Using basic handler - no exception handling\\n2020-04-11 20:41:47,046|msrest.service_client|DEBUG|Accept header absent and forced to application/json\\n2020-04-11 20:41:47,047|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2020-04-11 20:41:47,047|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Adding task 9__log_batch to queue of approximate size: 9\\n2020-04-11 20:41:47,047|msrest.http_logger|DEBUG|Request URL: 'https://southcentralus.experiments.azureml.net/history/v1.0/subscriptions/c1d0a0ea-bf6e-4c1c-8b55-f1bdb0208df8/resourceGroups/awe-cirrus-rg/providers/Microsoft.MachineLearningServices/workspaces/cirrustest2/experiments/tf-cluster-multi-gpu/runs/tf-cluster-multi-gpu_1586637483_41828672/batch/metrics'\\n2020-04-11 20:41:47,047|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2020-04-11 20:41:47,047|msrest.http_logger|DEBUG|Request method: 'POST'\\n2020-04-11 20:41:47,047|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2020-04-11 20:41:47,048|msrest.http_logger|DEBUG|Request headers:\\n2020-04-11 20:41:47,048|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2020-04-11 20:41:47,048|msrest.http_logger|DEBUG|    'Accept': 'application/json'\\n2020-04-11 20:41:47,048|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2020-04-11 20:41:47,048|msrest.http_logger|DEBUG|    'Content-Type': 'application/json-patch+json; charset=utf-8'\\n2020-04-11 20:41:47,048|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2020-04-11 20:41:47,048|msrest.http_logger|DEBUG|    'x-ms-client-request-id': 'c965d8ae-a3c5-4115-b6eb-08a646aee0b3'\\n2020-04-11 20:41:47,048|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2020-04-11 20:41:47,048|msrest.http_logger|DEBUG|    'request-id': 'c965d8ae-a3c5-4115-b6eb-08a646aee0b3'\\n2020-04-11 20:41:47,048|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2020-04-11 20:41:47,049|msrest.http_logger|DEBUG|    'Content-Length': '693'\\n2020-04-11 20:41:47,049|msrest.http_logger|DEBUG|    'User-Agent': 'python/3.6.9 (Linux-4.15.0-1067-azure-x86_64-with-Ubuntu-18.04-bionic) msrest/0.6.13 azureml._restclient/core.1.2.0 sdk_run'\\n2020-04-11 20:41:47,049|msrest.http_logger|DEBUG|Request body:\\n2020-04-11 20:41:47,049|msrest.http_logger|DEBUG|{\\\"values\\\": [{\\\"metricId\\\": \\\"6addab19-e893-4ff6-a165-edf33b53694a\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2020-04-11T20:41:46.107687Z\\\", \\\"name\\\": \\\"Loss\\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"Loss\\\": 0.07064146853983402}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"Loss\\\", \\\"name\\\": \\\"Loss\\\", \\\"type\\\": \\\"float\\\"}]}}, {\\\"metricId\\\": \\\"ae9c3e3e-ab8a-4c57-9bc2-38b5f7b30732\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2020-04-11T20:41:46.107941Z\\\", \\\"name\\\": \\\"Accuracy\\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"Accuracy\\\": 2.4414061883248905e-08}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"Accuracy\\\", \\\"name\\\": \\\"Accuracy\\\", \\\"type\\\": \\\"float\\\"}]}}]}\\n2020-04-11 20:41:47,049|msrest.universal_http|DEBUG|Configuring redirects: allow=True, max=30\\n2020-04-11 20:41:47,049|msrest.universal_http|DEBUG|Configuring request: timeout=100, verify=True, cert=None\\n2020-04-11 20:41:47,049|msrest.universal_http|DEBUG|Configuring proxies: ''\\n2020-04-11 20:41:47,049|msrest.universal_http|DEBUG|Evaluate proxies against ENV settings: True\\n2020-04-11 20:41:47,301|msrest.http_logger|DEBUG|Response status: 200\\n2020-04-11 20:41:47,301|msrest.http_logger|DEBUG|Response headers:\\n2020-04-11 20:41:47,301|msrest.http_logger|DEBUG|    'Date': 'Sat, 11 Apr 2020 20:41:47 GMT'\\n2020-04-11 20:41:47,301|msrest.http_logger|DEBUG|    'Content-Length': '0'\\n2020-04-11 20:41:47,301|msrest.http_logger|DEBUG|    'Connection': 'keep-alive'\\n2020-04-11 20:41:47,301|msrest.http_logger|DEBUG|    'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d'\\n2020-04-11 20:41:47,301|msrest.http_logger|DEBUG|    'x-ms-client-request-id': 'c965d8ae-a3c5-4115-b6eb-08a646aee0b3'\\n2020-04-11 20:41:47,301|msrest.http_logger|DEBUG|    'x-ms-client-session-id': ''\\n2020-04-11 20:41:47,302|msrest.http_logger|DEBUG|    'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'\\n2020-04-11 20:41:47,302|msrest.http_logger|DEBUG|Response content:\\n2020-04-11 20:41:47,302|msrest.http_logger|DEBUG|\\n2020-04-11 20:41:47,303|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[STOP]\\n2020-04-11 20:42:00,273|azureml.core._metrics|DEBUG|Converted key Loss of value 0.06746331214904785 to 0.06746331214904785.\\n\\n2020-04-11 20:42:00,273|azureml.core._metrics|DEBUG|Converted key Accuracy of value 2.7465819840699623e-08 to 2.7465819840699623e-08.\\n\\n2020-04-11 20:42:01,069|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2020-04-11 20:42:01,069|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2020-04-11 20:42:01,070|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Batch size 2.\\n2020-04-11 20:42:01,070|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2020-04-11 20:42:01,070|azureml._restclient.clientbase.WorkerPool|DEBUG|submitting future: _log_batch\\n2020-04-11 20:42:01,070|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2020-04-11 20:42:01,071|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[START]\\n2020-04-11 20:42:01,071|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2020-04-11 20:42:01,071|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch.10__log_batch|DEBUG|Using basic handler - no exception handling\\n2020-04-11 20:42:01,072|msrest.service_client|DEBUG|Accept header absent and forced to application/json\\n2020-04-11 20:42:01,072|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2020-04-11 20:42:01,072|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Adding task 10__log_batch to queue of approximate size: 10\\n2020-04-11 20:42:01,073|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2020-04-11 20:42:01,073|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2020-04-11 20:42:01,073|msrest.http_logger|DEBUG|Request URL: 'https://southcentralus.experiments.azureml.net/history/v1.0/subscriptions/c1d0a0ea-bf6e-4c1c-8b55-f1bdb0208df8/resourceGroups/awe-cirrus-rg/providers/Microsoft.MachineLearningServices/workspaces/cirrustest2/experiments/tf-cluster-multi-gpu/runs/tf-cluster-multi-gpu_1586637483_41828672/batch/metrics'\\n2020-04-11 20:42:01,073|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2020-04-11 20:42:01,073|msrest.http_logger|DEBUG|Request method: 'POST'\\n2020-04-11 20:42:01,074|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2020-04-11 20:42:01,074|msrest.http_logger|DEBUG|Request headers:\\n2020-04-11 20:42:01,074|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2020-04-11 20:42:01,074|msrest.http_logger|DEBUG|    'Accept': 'application/json'\\n2020-04-11 20:42:01,074|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2020-04-11 20:42:01,074|msrest.http_logger|DEBUG|    'Content-Type': 'application/json-patch+json; charset=utf-8'\\n2020-04-11 20:42:01,074|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2020-04-11 20:42:01,074|msrest.http_logger|DEBUG|    'x-ms-client-request-id': 'f151ea6a-1c56-4c69-9f5e-dff65a85d074'\\n2020-04-11 20:42:01,074|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2020-04-11 20:42:01,075|msrest.http_logger|DEBUG|    'request-id': 'f151ea6a-1c56-4c69-9f5e-dff65a85d074'\\n2020-04-11 20:42:01,075|msrest.http_logger|DEBUG|    'Content-Length': '693'\\n2020-04-11 20:42:01,075|msrest.http_logger|DEBUG|    'User-Agent': 'python/3.6.9 (Linux-4.15.0-1067-azure-x86_64-with-Ubuntu-18.04-bionic) msrest/0.6.13 azureml._restclient/core.1.2.0 sdk_run'\\n2020-04-11 20:42:01,075|msrest.http_logger|DEBUG|Request body:\\n2020-04-11 20:42:01,075|msrest.http_logger|DEBUG|{\\\"values\\\": [{\\\"metricId\\\": \\\"9b395a73-fcd0-4a53-a082-9a334366dadb\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2020-04-11T20:42:00.273737Z\\\", \\\"name\\\": \\\"Loss\\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"Loss\\\": 0.06746331214904785}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"Loss\\\", \\\"name\\\": \\\"Loss\\\", \\\"type\\\": \\\"float\\\"}]}}, {\\\"metricId\\\": \\\"cb55440b-edfa-4e13-8ee6-26c5385e9104\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2020-04-11T20:42:00.273972Z\\\", \\\"name\\\": \\\"Accuracy\\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"Accuracy\\\": 2.7465819840699623e-08}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"Accuracy\\\", \\\"name\\\": \\\"Accuracy\\\", \\\"type\\\": \\\"float\\\"}]}}]}\\n2020-04-11 20:42:01,075|msrest.universal_http|DEBUG|Configuring redirects: allow=True, max=30\\n2020-04-11 20:42:01,075|msrest.universal_http|DEBUG|Configuring request: timeout=100, verify=True, cert=None\\n2020-04-11 20:42:01,075|msrest.universal_http|DEBUG|Configuring proxies: ''\\n2020-04-11 20:42:01,076|msrest.universal_http|DEBUG|Evaluate proxies against ENV settings: True\\n2020-04-11 20:42:01,213|msrest.http_logger|DEBUG|Response status: 200\\n2020-04-11 20:42:01,213|msrest.http_logger|DEBUG|Response headers:\\n2020-04-11 20:42:01,213|msrest.http_logger|DEBUG|    'Date': 'Sat, 11 Apr 2020 20:42:01 GMT'\\n2020-04-11 20:42:01,213|msrest.http_logger|DEBUG|    'Content-Length': '0'\\n2020-04-11 20:42:01,213|msrest.http_logger|DEBUG|    'Connection': 'keep-alive'\\n2020-04-11 20:42:01,213|msrest.http_logger|DEBUG|    'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d'\\n2020-04-11 20:42:01,213|msrest.http_logger|DEBUG|    'x-ms-client-request-id': 'f151ea6a-1c56-4c69-9f5e-dff65a85d074'\\n2020-04-11 20:42:01,213|msrest.http_logger|DEBUG|    'x-ms-client-session-id': ''\\n2020-04-11 20:42:01,213|msrest.http_logger|DEBUG|    'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'\\n2020-04-11 20:42:01,214|msrest.http_logger|DEBUG|Response content:\\n2020-04-11 20:42:01,214|msrest.http_logger|DEBUG|\\n2020-04-11 20:42:01,215|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[STOP]\\n2020-04-11 20:42:07,130|azureml.core.authentication|DEBUG|Time to expire 1814159.869635 seconds\\n2020-04-11 20:42:14,179|azureml.core._metrics|DEBUG|Converted key Loss of value 0.06481637537479401 to 0.06481637537479401.\\n\\n2020-04-11 20:42:14,179|azureml.core._metrics|DEBUG|Converted key Accuracy of value 2.7465819840699623e-08 to 2.7465819840699623e-08.\\n\\n2020-04-11 20:42:15,079|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2020-04-11 20:42:15,080|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2020-04-11 20:42:15,080|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Batch size 2.\\n2020-04-11 20:42:15,080|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2020-04-11 20:42:15,080|azureml._restclient.clientbase.WorkerPool|DEBUG|submitting future: _log_batch\\n2020-04-11 20:42:15,080|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2020-04-11 20:42:15,101|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2020-04-11 20:42:15,101|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[START]\\n2020-04-11 20:42:15,102|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2020-04-11 20:42:15,102|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch.11__log_batch|DEBUG|Using basic handler - no exception handling\\n2020-04-11 20:42:15,103|msrest.service_client|DEBUG|Accept header absent and forced to application/json\\n2020-04-11 20:42:15,103|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2020-04-11 20:42:15,103|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Adding task 11__log_batch to queue of approximate size: 11\\n2020-04-11 20:42:15,103|msrest.http_logger|DEBUG|Request URL: 'https://southcentralus.experiments.azureml.net/history/v1.0/subscriptions/c1d0a0ea-bf6e-4c1c-8b55-f1bdb0208df8/resourceGroups/awe-cirrus-rg/providers/Microsoft.MachineLearningServices/workspaces/cirrustest2/experiments/tf-cluster-multi-gpu/runs/tf-cluster-multi-gpu_1586637483_41828672/batch/metrics'\\n2020-04-11 20:42:15,104|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2020-04-11 20:42:15,104|msrest.http_logger|DEBUG|Request method: 'POST'\\n2020-04-11 20:42:15,104|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2020-04-11 20:42:15,104|msrest.http_logger|DEBUG|Request headers:\\n2020-04-11 20:42:15,104|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2020-04-11 20:42:15,104|msrest.http_logger|DEBUG|    'Accept': 'application/json'\\n2020-04-11 20:42:15,104|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2020-04-11 20:42:15,105|msrest.http_logger|DEBUG|    'Content-Type': 'application/json-patch+json; charset=utf-8'\\n2020-04-11 20:42:15,105|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2020-04-11 20:42:15,105|msrest.http_logger|DEBUG|    'x-ms-client-request-id': 'd4371ded-ac63-49ac-b8a0-12ba6beb8832'\\n2020-04-11 20:42:15,105|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2020-04-11 20:42:15,105|msrest.http_logger|DEBUG|    'request-id': 'd4371ded-ac63-49ac-b8a0-12ba6beb8832'\\n2020-04-11 20:42:15,105|msrest.http_logger|DEBUG|    'Content-Length': '693'\\n2020-04-11 20:42:15,105|msrest.http_logger|DEBUG|    'User-Agent': 'python/3.6.9 (Linux-4.15.0-1067-azure-x86_64-with-Ubuntu-18.04-bionic) msrest/0.6.13 azureml._restclient/core.1.2.0 sdk_run'\\n2020-04-11 20:42:15,105|msrest.http_logger|DEBUG|Request body:\\n2020-04-11 20:42:15,105|msrest.http_logger|DEBUG|{\\\"values\\\": [{\\\"metricId\\\": \\\"9c38287c-192b-4d5a-9ff8-cf261a755bdc\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2020-04-11T20:42:14.179406Z\\\", \\\"name\\\": \\\"Loss\\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"Loss\\\": 0.06481637537479401}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"Loss\\\", \\\"name\\\": \\\"Loss\\\", \\\"type\\\": \\\"float\\\"}]}}, {\\\"metricId\\\": \\\"346f2819-900f-417f-bad7-8d47d411a9d7\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2020-04-11T20:42:14.179656Z\\\", \\\"name\\\": \\\"Accuracy\\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"Accuracy\\\": 2.7465819840699623e-08}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"Accuracy\\\", \\\"name\\\": \\\"Accuracy\\\", \\\"type\\\": \\\"float\\\"}]}}]}\\n2020-04-11 20:42:15,106|msrest.universal_http|DEBUG|Configuring redirects: allow=True, max=30\\n2020-04-11 20:42:15,106|msrest.universal_http|DEBUG|Configuring request: timeout=100, verify=True, cert=None\\n2020-04-11 20:42:15,106|msrest.universal_http|DEBUG|Configuring proxies: ''\\n2020-04-11 20:42:15,106|msrest.universal_http|DEBUG|Evaluate proxies against ENV settings: True\\n2020-04-11 20:42:15,242|msrest.http_logger|DEBUG|Response status: 200\\n2020-04-11 20:42:15,242|msrest.http_logger|DEBUG|Response headers:\\n2020-04-11 20:42:15,242|msrest.http_logger|DEBUG|    'Date': 'Sat, 11 Apr 2020 20:42:15 GMT'\\n2020-04-11 20:42:15,242|msrest.http_logger|DEBUG|    'Content-Length': '0'\\n2020-04-11 20:42:15,242|msrest.http_logger|DEBUG|    'Connection': 'keep-alive'\\n2020-04-11 20:42:15,242|msrest.http_logger|DEBUG|    'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d'\\n2020-04-11 20:42:15,242|msrest.http_logger|DEBUG|    'x-ms-client-request-id': 'd4371ded-ac63-49ac-b8a0-12ba6beb8832'\\n2020-04-11 20:42:15,243|msrest.http_logger|DEBUG|    'x-ms-client-session-id': ''\\n2020-04-11 20:42:15,243|msrest.http_logger|DEBUG|    'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'\\n2020-04-11 20:42:15,243|msrest.http_logger|DEBUG|Response content:\\n2020-04-11 20:42:15,243|msrest.http_logger|DEBUG|\\n2020-04-11 20:42:15,244|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[STOP]\\n2020-04-11 20:42:27,698|azureml.core._metrics|DEBUG|Converted key Loss of value 0.06257621053606272 to 0.06257621053606272.\\n\\n2020-04-11 20:42:27,698|azureml.core._metrics|DEBUG|Converted key Accuracy of value 2.7465819840699623e-08 to 2.7465819840699623e-08.\\n\\n2020-04-11 20:42:28,108|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2020-04-11 20:42:28,108|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2020-04-11 20:42:28,109|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Batch size 2.\\n2020-04-11 20:42:28,109|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2020-04-11 20:42:28,109|azureml._restclient.clientbase.WorkerPool|DEBUG|submitting future: _log_batch\\n2020-04-11 20:42:28,109|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2020-04-11 20:42:28,110|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[START]\\n2020-04-11 20:42:28,110|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2020-04-11 20:42:28,117|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch.12__log_batch|DEBUG|Using basic handler - no exception handling\\n2020-04-11 20:42:28,120|msrest.service_client|DEBUG|Accept header absent and forced to application/json\\n2020-04-11 20:42:28,120|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2020-04-11 20:42:28,121|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Adding task 12__log_batch to queue of approximate size: 12\\n2020-04-11 20:42:28,121|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2020-04-11 20:42:28,121|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2020-04-11 20:42:28,121|msrest.http_logger|DEBUG|Request URL: 'https://southcentralus.experiments.azureml.net/history/v1.0/subscriptions/c1d0a0ea-bf6e-4c1c-8b55-f1bdb0208df8/resourceGroups/awe-cirrus-rg/providers/Microsoft.MachineLearningServices/workspaces/cirrustest2/experiments/tf-cluster-multi-gpu/runs/tf-cluster-multi-gpu_1586637483_41828672/batch/metrics'\\n2020-04-11 20:42:28,122|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2020-04-11 20:42:28,122|msrest.http_logger|DEBUG|Request method: 'POST'\\n2020-04-11 20:42:28,122|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2020-04-11 20:42:28,122|msrest.http_logger|DEBUG|Request headers:\\n2020-04-11 20:42:28,122|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2020-04-11 20:42:28,122|msrest.http_logger|DEBUG|    'Accept': 'application/json'\\n2020-04-11 20:42:28,122|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2020-04-11 20:42:28,123|msrest.http_logger|DEBUG|    'Content-Type': 'application/json-patch+json; charset=utf-8'\\n2020-04-11 20:42:28,123|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2020-04-11 20:42:28,123|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '991b278c-b1c4-46e3-9c03-98ae7773b73a'\\n2020-04-11 20:42:28,123|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2020-04-11 20:42:28,123|msrest.http_logger|DEBUG|    'request-id': '991b278c-b1c4-46e3-9c03-98ae7773b73a'\\n2020-04-11 20:42:28,123|msrest.http_logger|DEBUG|    'Content-Length': '690'\\n2020-04-11 20:42:28,123|msrest.http_logger|DEBUG|    'User-Agent': 'python/3.6.9 (Linux-4.15.0-1067-azure-x86_64-with-Ubuntu-18.04-bionic) msrest/0.6.13 azureml._restclient/core.1.2.0 sdk_run'\\n2020-04-11 20:42:28,123|msrest.http_logger|DEBUG|Request body:\\n2020-04-11 20:42:28,123|msrest.http_logger|DEBUG|{\\\"values\\\": [{\\\"metricId\\\": \\\"5f27cf1b-5602-47fd-8ea4-e15230713728\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2020-04-11T20:42:27.698749Z\\\", \\\"name\\\": \\\"Loss\\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"Loss\\\": 0.06257621053606272}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"Loss\\\", \\\"name\\\": \\\"Loss\\\", \\\"type\\\": \\\"float\\\"}]}}, {\\\"metricId\\\": \\\"b1d1242a-3baa-41d2-9826-48ee717442eb\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2020-04-11T20:42:27.699Z\\\", \\\"name\\\": \\\"Accuracy\\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"Accuracy\\\": 2.7465819840699623e-08}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"Accuracy\\\", \\\"name\\\": \\\"Accuracy\\\", \\\"type\\\": \\\"float\\\"}]}}]}\\n2020-04-11 20:42:28,124|msrest.universal_http|DEBUG|Configuring redirects: allow=True, max=30\\n2020-04-11 20:42:28,124|msrest.universal_http|DEBUG|Configuring request: timeout=100, verify=True, cert=None\\n2020-04-11 20:42:28,124|msrest.universal_http|DEBUG|Configuring proxies: ''\\n2020-04-11 20:42:28,124|msrest.universal_http|DEBUG|Evaluate proxies against ENV settings: True\\n2020-04-11 20:42:28,354|msrest.http_logger|DEBUG|Response status: 200\\n2020-04-11 20:42:28,354|msrest.http_logger|DEBUG|Response headers:\\n2020-04-11 20:42:28,355|msrest.http_logger|DEBUG|    'Date': 'Sat, 11 Apr 2020 20:42:28 GMT'\\n2020-04-11 20:42:28,355|msrest.http_logger|DEBUG|    'Content-Length': '0'\\n2020-04-11 20:42:28,355|msrest.http_logger|DEBUG|    'Connection': 'keep-alive'\\n2020-04-11 20:42:28,355|msrest.http_logger|DEBUG|    'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d'\\n2020-04-11 20:42:28,355|msrest.http_logger|DEBUG|    'x-ms-client-request-id': '991b278c-b1c4-46e3-9c03-98ae7773b73a'\\n2020-04-11 20:42:28,355|msrest.http_logger|DEBUG|    'x-ms-client-session-id': ''\\n2020-04-11 20:42:28,355|msrest.http_logger|DEBUG|    'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'\\n2020-04-11 20:42:28,355|msrest.http_logger|DEBUG|Response content:\\n2020-04-11 20:42:28,355|msrest.http_logger|DEBUG|\\n2020-04-11 20:42:28,357|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[STOP]\\n2020-04-11 20:42:37,130|azureml.core.authentication|DEBUG|Time to expire 1814129.86946 seconds\\n2020-04-11 20:42:40,834|azureml.core._metrics|DEBUG|Converted key Loss of value 0.06065903708338737 to 0.06065903708338737.\\n\\n2020-04-11 20:42:40,834|azureml.core._metrics|DEBUG|Converted key Accuracy of value 2.7465819840699623e-08 to 2.7465819840699623e-08.\\n\\n2020-04-11 20:42:41,136|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2020-04-11 20:42:41,137|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2020-04-11 20:42:41,137|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Batch size 2.\\n2020-04-11 20:42:41,137|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2020-04-11 20:42:41,137|azureml._restclient.clientbase.WorkerPool|DEBUG|submitting future: _log_batch\\n2020-04-11 20:42:41,137|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2020-04-11 20:42:41,138|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[START]\\n2020-04-11 20:42:41,138|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2020-04-11 20:42:41,138|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch.13__log_batch|DEBUG|Using basic handler - no exception handling\\n2020-04-11 20:42:41,139|msrest.service_client|DEBUG|Accept header absent and forced to application/json\\n2020-04-11 20:42:41,160|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2020-04-11 20:42:41,160|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Adding task 13__log_batch to queue of approximate size: 13\\n2020-04-11 20:42:41,161|msrest.http_logger|DEBUG|Request URL: 'https://southcentralus.experiments.azureml.net/history/v1.0/subscriptions/c1d0a0ea-bf6e-4c1c-8b55-f1bdb0208df8/resourceGroups/awe-cirrus-rg/providers/Microsoft.MachineLearningServices/workspaces/cirrustest2/experiments/tf-cluster-multi-gpu/runs/tf-cluster-multi-gpu_1586637483_41828672/batch/metrics'\\n2020-04-11 20:42:41,161|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2020-04-11 20:42:41,161|msrest.http_logger|DEBUG|Request method: 'POST'\\n2020-04-11 20:42:41,161|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2020-04-11 20:42:41,161|msrest.http_logger|DEBUG|Request headers:\\n2020-04-11 20:42:41,161|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2020-04-11 20:42:41,162|msrest.http_logger|DEBUG|    'Accept': 'application/json'\\n2020-04-11 20:42:41,162|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2020-04-11 20:42:41,162|msrest.http_logger|DEBUG|    'Content-Type': 'application/json-patch+json; charset=utf-8'\\n2020-04-11 20:42:41,162|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2020-04-11 20:42:41,162|msrest.http_logger|DEBUG|    'x-ms-client-request-id': 'fcec7afd-d1af-4876-be58-070c06fdd8d9'\\n2020-04-11 20:42:41,162|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2020-04-11 20:42:41,162|msrest.http_logger|DEBUG|    'request-id': 'fcec7afd-d1af-4876-be58-070c06fdd8d9'\\n2020-04-11 20:42:41,162|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2020-04-11 20:42:41,162|msrest.http_logger|DEBUG|    'Content-Length': '693'\\n2020-04-11 20:42:41,163|msrest.http_logger|DEBUG|    'User-Agent': 'python/3.6.9 (Linux-4.15.0-1067-azure-x86_64-with-Ubuntu-18.04-bionic) msrest/0.6.13 azureml._restclient/core.1.2.0 sdk_run'\\n2020-04-11 20:42:41,163|msrest.http_logger|DEBUG|Request body:\\n2020-04-11 20:42:41,163|msrest.http_logger|DEBUG|{\\\"values\\\": [{\\\"metricId\\\": \\\"e7403440-ed06-4cb5-ad63-4f008e878964\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2020-04-11T20:42:40.834556Z\\\", \\\"name\\\": \\\"Loss\\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"Loss\\\": 0.06065903708338737}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"Loss\\\", \\\"name\\\": \\\"Loss\\\", \\\"type\\\": \\\"float\\\"}]}}, {\\\"metricId\\\": \\\"5a1d7130-f060-4012-a14c-b05bda11bf24\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2020-04-11T20:42:40.834814Z\\\", \\\"name\\\": \\\"Accuracy\\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"Accuracy\\\": 2.7465819840699623e-08}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"Accuracy\\\", \\\"name\\\": \\\"Accuracy\\\", \\\"type\\\": \\\"float\\\"}]}}]}\\n2020-04-11 20:42:41,163|msrest.universal_http|DEBUG|Configuring redirects: allow=True, max=30\\n2020-04-11 20:42:41,163|msrest.universal_http|DEBUG|Configuring request: timeout=100, verify=True, cert=None\\n2020-04-11 20:42:41,163|msrest.universal_http|DEBUG|Configuring proxies: ''\\n2020-04-11 20:42:41,163|msrest.universal_http|DEBUG|Evaluate proxies against ENV settings: True\\n2020-04-11 20:42:41,263|msrest.http_logger|DEBUG|Response status: 200\\n2020-04-11 20:42:41,264|msrest.http_logger|DEBUG|Response headers:\\n2020-04-11 20:42:41,264|msrest.http_logger|DEBUG|    'Date': 'Sat, 11 Apr 2020 20:42:41 GMT'\\n2020-04-11 20:42:41,264|msrest.http_logger|DEBUG|    'Content-Length': '0'\\n2020-04-11 20:42:41,264|msrest.http_logger|DEBUG|    'Connection': 'keep-alive'\\n2020-04-11 20:42:41,264|msrest.http_logger|DEBUG|    'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d'\\n2020-04-11 20:42:41,264|msrest.http_logger|DEBUG|    'x-ms-client-request-id': 'fcec7afd-d1af-4876-be58-070c06fdd8d9'\\n2020-04-11 20:42:41,264|msrest.http_logger|DEBUG|    'x-ms-client-session-id': ''\\n2020-04-11 20:42:41,264|msrest.http_logger|DEBUG|    'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'\\n2020-04-11 20:42:41,264|msrest.http_logger|DEBUG|Response content:\\n2020-04-11 20:42:41,264|msrest.http_logger|DEBUG|\\n2020-04-11 20:42:41,266|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[STOP]\\n2020-04-11 20:42:54,514|azureml.core._metrics|DEBUG|Converted key Loss of value 0.05893784236162901 to 0.05893784236162901.\\n\\n2020-04-11 20:42:54,514|azureml.core._metrics|DEBUG|Converted key Accuracy of value 2.7465819840699623e-08 to 2.7465819840699623e-08.\\n\\n2020-04-11 20:42:55,148|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2020-04-11 20:42:55,148|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2020-04-11 20:42:55,149|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Batch size 2.\\n2020-04-11 20:42:55,149|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2020-04-11 20:42:55,149|azureml._restclient.clientbase.WorkerPool|DEBUG|submitting future: _log_batch\\n2020-04-11 20:42:55,149|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2020-04-11 20:42:55,150|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[START]\\n2020-04-11 20:42:55,150|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2020-04-11 20:42:55,150|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch.14__log_batch|DEBUG|Using basic handler - no exception handling\\n2020-04-11 20:42:55,151|msrest.service_client|DEBUG|Accept header absent and forced to application/json\\n2020-04-11 20:42:55,151|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2020-04-11 20:42:55,151|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Adding task 14__log_batch to queue of approximate size: 14\\n2020-04-11 20:42:55,152|msrest.universal_http.requests|DEBUG|Configuring retry: max_retries=3, backoff_factor=0.8, max_backoff=90\\n2020-04-11 20:42:55,152|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2020-04-11 20:42:55,152|msrest.http_logger|DEBUG|Request URL: 'https://southcentralus.experiments.azureml.net/history/v1.0/subscriptions/c1d0a0ea-bf6e-4c1c-8b55-f1bdb0208df8/resourceGroups/awe-cirrus-rg/providers/Microsoft.MachineLearningServices/workspaces/cirrustest2/experiments/tf-cluster-multi-gpu/runs/tf-cluster-multi-gpu_1586637483_41828672/batch/metrics'\\n2020-04-11 20:42:55,152|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2020-04-11 20:42:55,152|msrest.http_logger|DEBUG|Request method: 'POST'\\n2020-04-11 20:42:55,153|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2020-04-11 20:42:55,153|msrest.http_logger|DEBUG|Request headers:\\n2020-04-11 20:42:55,153|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2020-04-11 20:42:55,153|msrest.http_logger|DEBUG|    'Accept': 'application/json'\\n2020-04-11 20:42:55,153|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2020-04-11 20:42:55,153|msrest.http_logger|DEBUG|    'Content-Type': 'application/json-patch+json; charset=utf-8'\\n2020-04-11 20:42:55,153|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2020-04-11 20:42:55,153|msrest.http_logger|DEBUG|    'x-ms-client-request-id': 'a661e3ba-767d-400d-92c1-067f230dd87d'\\n2020-04-11 20:42:55,153|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2020-04-11 20:42:55,154|msrest.http_logger|DEBUG|    'request-id': 'a661e3ba-767d-400d-92c1-067f230dd87d'\\n2020-04-11 20:42:55,154|msrest.http_logger|DEBUG|    'Content-Length': '691'\\n2020-04-11 20:42:55,154|msrest.http_logger|DEBUG|    'User-Agent': 'python/3.6.9 (Linux-4.15.0-1067-azure-x86_64-with-Ubuntu-18.04-bionic) msrest/0.6.13 azureml._restclient/core.1.2.0 sdk_run'\\n2020-04-11 20:42:55,154|msrest.http_logger|DEBUG|Request body:\\n2020-04-11 20:42:55,154|msrest.http_logger|DEBUG|{\\\"values\\\": [{\\\"metricId\\\": \\\"bc71ec3c-9c40-470b-a3c1-2f3cddb87425\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2020-04-11T20:42:54.5143Z\\\", \\\"name\\\": \\\"Loss\\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"Loss\\\": 0.05893784236162901}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"Loss\\\", \\\"name\\\": \\\"Loss\\\", \\\"type\\\": \\\"float\\\"}]}}, {\\\"metricId\\\": \\\"9941675a-635f-4000-ae0f-797b90231967\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2020-04-11T20:42:54.514556Z\\\", \\\"name\\\": \\\"Accuracy\\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"Accuracy\\\": 2.7465819840699623e-08}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"Accuracy\\\", \\\"name\\\": \\\"Accuracy\\\", \\\"type\\\": \\\"float\\\"}]}}]}\\n2020-04-11 20:42:55,154|msrest.universal_http|DEBUG|Configuring redirects: allow=True, max=30\\n2020-04-11 20:42:55,154|msrest.universal_http|DEBUG|Configuring request: timeout=100, verify=True, cert=None\\n2020-04-11 20:42:55,154|msrest.universal_http|DEBUG|Configuring proxies: ''\\n2020-04-11 20:42:55,154|msrest.universal_http|DEBUG|Evaluate proxies against ENV settings: True\\n2020-04-11 20:42:55,400|msrest.http_logger|DEBUG|Response status: 200\\n2020-04-11 20:42:55,400|msrest.http_logger|DEBUG|Response headers:\\n2020-04-11 20:42:55,400|msrest.http_logger|DEBUG|    'Date': 'Sat, 11 Apr 2020 20:42:55 GMT'\\n2020-04-11 20:42:55,400|msrest.http_logger|DEBUG|    'Content-Length': '0'\\n2020-04-11 20:42:55,400|msrest.http_logger|DEBUG|    'Connection': 'keep-alive'\\n2020-04-11 20:42:55,400|msrest.http_logger|DEBUG|    'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d'\\n2020-04-11 20:42:55,400|msrest.http_logger|DEBUG|    'x-ms-client-request-id': 'a661e3ba-767d-400d-92c1-067f230dd87d'\\n2020-04-11 20:42:55,400|msrest.http_logger|DEBUG|    'x-ms-client-session-id': ''\\n2020-04-11 20:42:55,400|msrest.http_logger|DEBUG|    'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'\\n2020-04-11 20:42:55,401|msrest.http_logger|DEBUG|Response content:\\n2020-04-11 20:42:55,401|msrest.http_logger|DEBUG|\\n2020-04-11 20:42:55,402|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[STOP]\\n2020-04-11 20:43:07,130|azureml.core.authentication|DEBUG|Time to expire 1814099.869116 seconds\\n2020-04-11 20:43:07,493|azureml.core._metrics|DEBUG|Converted key Loss of value 0.05736836705356836 to 0.05736836705356836.\\n\\n2020-04-11 20:43:07,493|azureml.core._metrics|DEBUG|Converted key Accuracy of value 2.7465819840699623e-08 to 2.7465819840699623e-08.\\n\\n2020-04-11 20:43:08,160|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2020-04-11 20:43:08,160|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2020-04-11 20:43:08,160|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Batch size 2.\\n2020-04-11 20:43:08,160|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2020-04-11 20:43:08,161|azureml._restclient.clientbase.WorkerPool|DEBUG|submitting future: _log_batch\\n2020-04-11 20:43:08,161|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2020-04-11 20:43:08,161|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[START]\\n2020-04-11 20:43:08,161|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2020-04-11 20:43:08,161|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch.15__log_batch|DEBUG|Using basic handler - no exception handling\\n2020-04-11 20:43:08,163|msrest.service_client|DEBUG|Accept header absent and forced to application/json\\n2020-04-11 20:43:08,163|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2020-04-11 20:43:08,163|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|Adding task 15__log_batch to queue of approximate size: 15\\n2020-04-11 20:43:08,163|msrest.http_logger|DEBUG|Request URL: 'https://southcentralus.experiments.azureml.net/history/v1.0/subscriptions/c1d0a0ea-bf6e-4c1c-8b55-f1bdb0208df8/resourceGroups/awe-cirrus-rg/providers/Microsoft.MachineLearningServices/workspaces/cirrustest2/experiments/tf-cluster-multi-gpu/runs/tf-cluster-multi-gpu_1586637483_41828672/batch/metrics'\\n2020-04-11 20:43:08,163|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2020-04-11 20:43:08,163|msrest.http_logger|DEBUG|Request method: 'POST'\\n2020-04-11 20:43:08,164|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2020-04-11 20:43:08,164|msrest.http_logger|DEBUG|Request headers:\\n2020-04-11 20:43:08,164|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2020-04-11 20:43:08,164|msrest.http_logger|DEBUG|    'Accept': 'application/json'\\n2020-04-11 20:43:08,164|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2020-04-11 20:43:08,164|msrest.http_logger|DEBUG|    'Content-Type': 'application/json-patch+json; charset=utf-8'\\n2020-04-11 20:43:08,164|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2020-04-11 20:43:08,164|msrest.http_logger|DEBUG|    'x-ms-client-request-id': 'ef6a22b1-ce82-445d-b945-cab0bc2ea110'\\n2020-04-11 20:43:08,164|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2020-04-11 20:43:08,165|msrest.http_logger|DEBUG|    'request-id': 'ef6a22b1-ce82-445d-b945-cab0bc2ea110'\\n2020-04-11 20:43:08,165|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2020-04-11 20:43:08,165|msrest.http_logger|DEBUG|    'Content-Length': '693'\\n2020-04-11 20:43:08,165|msrest.http_logger|DEBUG|    'User-Agent': 'python/3.6.9 (Linux-4.15.0-1067-azure-x86_64-with-Ubuntu-18.04-bionic) msrest/0.6.13 azureml._restclient/core.1.2.0 sdk_run'\\n2020-04-11 20:43:08,165|msrest.http_logger|DEBUG|Request body:\\n2020-04-11 20:43:08,165|msrest.http_logger|DEBUG|{\\\"values\\\": [{\\\"metricId\\\": \\\"4eb8602a-a7c9-4e63-a647-f9569bbfedd0\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2020-04-11T20:43:07.493501Z\\\", \\\"name\\\": \\\"Loss\\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"Loss\\\": 0.05736836705356836}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"Loss\\\", \\\"name\\\": \\\"Loss\\\", \\\"type\\\": \\\"float\\\"}]}}, {\\\"metricId\\\": \\\"fffbb2af-20eb-4e55-b28b-1a613293d312\\\", \\\"metricType\\\": \\\"azureml.v1.scalar\\\", \\\"createdUtc\\\": \\\"2020-04-11T20:43:07.493776Z\\\", \\\"name\\\": \\\"Accuracy\\\", \\\"description\\\": \\\"\\\", \\\"numCells\\\": 1, \\\"cells\\\": [{\\\"Accuracy\\\": 2.7465819840699623e-08}], \\\"schema\\\": {\\\"numProperties\\\": 1, \\\"properties\\\": [{\\\"propertyId\\\": \\\"Accuracy\\\", \\\"name\\\": \\\"Accuracy\\\", \\\"type\\\": \\\"float\\\"}]}}]}\\n2020-04-11 20:43:08,165|msrest.universal_http|DEBUG|Configuring redirects: allow=True, max=30\\n2020-04-11 20:43:08,165|msrest.universal_http|DEBUG|Configuring request: timeout=100, verify=True, cert=None\\n2020-04-11 20:43:08,165|msrest.universal_http|DEBUG|Configuring proxies: ''\\n2020-04-11 20:43:08,165|msrest.universal_http|DEBUG|Evaluate proxies against ENV settings: True\\n2020-04-11 20:43:08,300|msrest.http_logger|DEBUG|Response status: 200\\n2020-04-11 20:43:08,300|msrest.http_logger|DEBUG|Response headers:\\n2020-04-11 20:43:08,300|msrest.http_logger|DEBUG|    'Date': 'Sat, 11 Apr 2020 20:43:08 GMT'\\n2020-04-11 20:43:08,300|msrest.http_logger|DEBUG|    'Content-Length': '0'\\n2020-04-11 20:43:08,300|msrest.http_logger|DEBUG|    'Connection': 'keep-alive'\\n2020-04-11 20:43:08,300|msrest.http_logger|DEBUG|    'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d'\\n2020-04-11 20:43:08,300|msrest.http_logger|DEBUG|    'x-ms-client-request-id': 'ef6a22b1-ce82-445d-b945-cab0bc2ea110'\\n2020-04-11 20:43:08,300|msrest.http_logger|DEBUG|    'x-ms-client-session-id': ''\\n2020-04-11 20:43:08,301|msrest.http_logger|DEBUG|    'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'\\n2020-04-11 20:43:08,301|msrest.http_logger|DEBUG|Response content:\\n2020-04-11 20:43:08,301|msrest.http_logger|DEBUG|\\n2020-04-11 20:43:08,302|azureml._SubmittedRun#tf-cluster-multi-gpu_1586637483_41828672.RunHistoryFacade.MetricsClient.post_batch-async:False|DEBUG|[STOP]\\n\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.2.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also periodically check the status of the run object, and navigate to Azure portal to monitor the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>tf-cluster-multi-gpu</td><td>tf-cluster-multi-gpu_1586637483_41828672</td><td>azureml.scriptrun</td><td>Starting</td><td><a href=\"https://ml.azure.com/experiments/tf-cluster-multi-gpu/runs/tf-cluster-multi-gpu_1586637483_41828672?wsid=/subscriptions/c1d0a0ea-bf6e-4c1c-8b55-f1bdb0208df8/resourcegroups/awe-cirrus-rg/workspaces/cirrustest2\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: tf-cluster-multi-gpu,\n",
       "Id: tf-cluster-multi-gpu_1586637483_41828672,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Starting)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: tf-cluster-multi-gpu_1586637483_41828672\n",
      "Web View: https://ml.azure.com/experiments/tf-cluster-multi-gpu/runs/tf-cluster-multi-gpu_1586637483_41828672?wsid=/subscriptions/c1d0a0ea-bf6e-4c1c-8b55-f1bdb0208df8/resourcegroups/awe-cirrus-rg/workspaces/cirrustest2\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_b822616ab430925d5a2e6f9f15b2b7b54543eed65414c1dfaec6e96f4ee3e50b_d.txt\n",
      "========================================================================================================================\n",
      "\n",
      "2020-04-11T20:38:25Z Starting output-watcher...\n",
      "2020-04-11T20:38:25Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "v2: Pulling from returncode13/tf-gpu-test\n",
      "Digest: sha256:731bf83ba0ce926e83a32069e290a554a941d6ae31af42e5546e5e3d41c746dd\n",
      "Status: Image is up to date for returncode13/tf-gpu-test:v2\n",
      "b6d28c84c7f3450fdc164da42ca038fed67f8ac6d516e1816dd250066ca8c28f\n",
      "2020/04/11 20:38:28 Version: 3.0.01172.0001 Branch: master Commit: d33e301a\n",
      "2020/04/11 20:38:28 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2020/04/11 20:38:28 Setting up Passwordless SSH in Container\n",
      "2020-04-11T20:38:28Z Setting up Passwordless SSH in Container\n",
      "dpkg: warning: downgrading libkrb5support0:amd64 from 1.16-2ubuntu0.1 to 1.13.2+dfsg-5ubuntu2.1\n",
      "(Reading database ... 16848 files and directories currently installed.)\n",
      "Preparing to unpack libkrb5support0_1.13.2+dfsg-5ubuntu2.1_amd64.deb ...\n",
      "Unpacking libkrb5support0:amd64 (1.13.2+dfsg-5ubuntu2.1) over (1.16-2ubuntu0.1) ...\n",
      "Setting up libkrb5support0:amd64 (1.13.2+dfsg-5ubuntu2.1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-compiler.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-ptxjitcompiler.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-fatbinaryloader.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-cfg.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libcuda.so.440.64.00 is empty, not checked.\n",
      "dpkg: warning: downgrading libk5crypto3:amd64 from 1.16-2ubuntu0.1 to 1.13.2+dfsg-5ubuntu2.1\n",
      "(Reading database ... 16848 files and directories currently installed.)\n",
      "Preparing to unpack libk5crypto3_1.13.2+dfsg-5ubuntu2.1_amd64.deb ...\n",
      "Unpacking libk5crypto3:amd64 (1.13.2+dfsg-5ubuntu2.1) over (1.16-2ubuntu0.1) ...\n",
      "Setting up libk5crypto3:amd64 (1.13.2+dfsg-5ubuntu2.1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-compiler.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-ptxjitcompiler.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-fatbinaryloader.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-cfg.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libcuda.so.440.64.00 is empty, not checked.\n",
      "dpkg: warning: downgrading libkeyutils1:amd64 from 1.5.9-9.2ubuntu2 to 1.5.9-8ubuntu1\n",
      "(Reading database ... 16848 files and directories currently installed.)\n",
      "Preparing to unpack libkeyutils1_1.5.9-8ubuntu1_amd64.deb ...\n",
      "Unpacking libkeyutils1:amd64 (1.5.9-8ubuntu1) over (1.5.9-9.2ubuntu2) ...\n",
      "Setting up libkeyutils1:amd64 (1.5.9-8ubuntu1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-compiler.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-ptxjitcompiler.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-fatbinaryloader.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-cfg.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libcuda.so.440.64.00 is empty, not checked.\n",
      "dpkg: warning: downgrading libkrb5-3:amd64 from 1.16-2ubuntu0.1 to 1.13.2+dfsg-5ubuntu2.1\n",
      "(Reading database ... 16848 files and directories currently installed.)\n",
      "Preparing to unpack libkrb5-3_1.13.2+dfsg-5ubuntu2.1_amd64.deb ...\n",
      "Unpacking libkrb5-3:amd64 (1.13.2+dfsg-5ubuntu2.1) over (1.16-2ubuntu0.1) ...\n",
      "Setting up libkrb5-3:amd64 (1.13.2+dfsg-5ubuntu2.1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-compiler.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-ptxjitcompiler.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-fatbinaryloader.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-cfg.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libcuda.so.440.64.00 is empty, not checked.\n",
      "dpkg: warning: downgrading libgssapi-krb5-2:amd64 from 1.16-2ubuntu0.1 to 1.13.2+dfsg-5ubuntu2.1\n",
      "(Reading database ... 16848 files and directories currently installed.)\n",
      "Preparing to unpack libgssapi-krb5-2_1.13.2+dfsg-5ubuntu2.1_amd64.deb ...\n",
      "Unpacking libgssapi-krb5-2:amd64 (1.13.2+dfsg-5ubuntu2.1) over (1.16-2ubuntu0.1) ...\n",
      "Setting up libgssapi-krb5-2:amd64 (1.13.2+dfsg-5ubuntu2.1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-compiler.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-ptxjitcompiler.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-fatbinaryloader.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-cfg.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libcuda.so.440.64.00 is empty, not checked.\n",
      "dpkg: warning: downgrading libssl1.0.0:amd64 from 1.0.2n-1ubuntu5.3 to 1.0.2g-1ubuntu4.15\n",
      "(Reading database ... 16848 files and directories currently installed.)\n",
      "Preparing to unpack libssl1.0.0_1.0.2g-1ubuntu4.15_amd64.deb ...\n",
      "Unpacking libssl1.0.0:amd64 (1.0.2g-1ubuntu4.15) over (1.0.2n-1ubuntu5.3) ...\n",
      "Setting up libssl1.0.0:amd64 (1.0.2g-1ubuntu4.15) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-compiler.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-ptxjitcompiler.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-fatbinaryloader.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-cfg.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libcuda.so.440.64.00 is empty, not checked.\n",
      "dpkg: warning: downgrading multiarch-support from 2.27-3ubuntu1 to 2.23-0ubuntu10\n",
      "(Reading database ... 16846 files and directories currently installed.)\n",
      "Preparing to unpack multiarch-support_2.23-0ubuntu10_amd64.deb ...\n",
      "Unpacking multiarch-support (2.23-0ubuntu10) over (2.27-3ubuntu1) ...\n",
      "Setting up multiarch-support (2.23-0ubuntu10) ...\n",
      "Selecting previously unselected package libwrap0:amd64.\n",
      "(Reading database ... 16846 files and directories currently installed.)\n",
      "Preparing to unpack libwrap0_7.6.q-25_amd64.deb ...\n",
      "Unpacking libwrap0:amd64 (7.6.q-25) ...\n",
      "Setting up libwrap0:amd64 (7.6.q-25) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-compiler.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-ptxjitcompiler.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-fatbinaryloader.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-cfg.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libcuda.so.440.64.00 is empty, not checked.\n",
      "dpkg: warning: downgrading libbsd0:amd64 from 0.8.7-1ubuntu0.1 to 0.8.2-1\n",
      "(Reading database ... 16857 files and directories currently installed.)\n",
      "Preparing to unpack libbsd0_0.8.2-1_amd64.deb ...\n",
      "Unpacking libbsd0:amd64 (0.8.2-1) over (0.8.7-1ubuntu0.1) ...\n",
      "Setting up libbsd0:amd64 (0.8.2-1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-compiler.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-ptxjitcompiler.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-fatbinaryloader.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-cfg.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libcuda.so.440.64.00 is empty, not checked.\n",
      "dpkg: warning: downgrading libedit2:amd64 from 3.1-20170329-1 to 3.1-20150325-1ubuntu2\n",
      "(Reading database ... 16857 files and directories currently installed.)\n",
      "Preparing to unpack libedit2_3.1-20150325-1ubuntu2_amd64.deb ...\n",
      "Unpacking libedit2:amd64 (3.1-20150325-1ubuntu2) over (3.1-20170329-1) ...\n",
      "Setting up libedit2:amd64 (3.1-20150325-1ubuntu2) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-compiler.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-ptxjitcompiler.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-fatbinaryloader.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-cfg.so.440.64.00 is empty, not checked.\n",
      "/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libcuda.so.440.64.00 is empty, not checked.\n",
      "dpkg: warning: downgrading openssh-client from 1:7.6p1-4ubuntu0.3 to 1:7.2p2-4ubuntu2.8\n",
      "(Reading database ... 16857 files and directories currently installed.)\n",
      "Preparing to unpack openssh-client_7.2p2-4ubuntu2.8_amd64.deb ...\n",
      "Unpacking openssh-client (1:7.2p2-4ubuntu2.8) over (1:7.6p1-4ubuntu0.3) ...\n",
      "Setting up openssh-client (1:7.2p2-4ubuntu2.8) ...\n",
      "Installing new version of config file /etc/ssh/moduli ...\n",
      "Installing new version of config file /etc/ssh/ssh_config ...\n",
      "Selecting previously unselected package openssh-sftp-server.\n",
      "(Reading database ... 16856 files and directories currently installed.)\n",
      "Preparing to unpack openssh-sftp-server_7.2p2-4ubuntu2.8_amd64.deb ...\n",
      "Unpacking openssh-sftp-server (1:7.2p2-4ubuntu2.8) ...\n",
      "Setting up openssh-sftp-server (1:7.2p2-4ubuntu2.8) ...\n",
      "Selecting previously unselected package openssh-server.\n",
      "(Reading database ... 16860 files and directories currently installed.)\n",
      "Preparing to unpack openssh-server_7.2p2-4ubuntu2.8_amd64.deb ...\n",
      "Unpacking openssh-server (1:7.2p2-4ubuntu2.8) ...\n",
      "Setting up openssh-server (1:7.2p2-4ubuntu2.8) ...\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_b822616ab430925d5a2e6f9f15b2b7b54543eed65414c1dfaec6e96f4ee3e50b_d.txt\n",
      "===============================================================================================================\n",
      "\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 455\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ keras_mnist-gpu.py ] with arguments: ['--batch-size', '50', '--first-layer-neurons', '300', '--second-layer-neurons', '100', '--learning-rate', '0.001']\n",
      "After variable expansion, calling script [ keras_mnist-gpu.py ] with arguments: ['--batch-size', '50', '--first-layer-neurons', '300', '--second-layer-neurons', '100', '--learning-rate', '0.001']\n",
      "\n",
      "Keras version: 2.2.4-tf\n",
      "Tensorflow version: 2.0.1\n",
      "2020-04-11 20:38:39.217521: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-04-11 20:38:39.224608: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2596985000 Hz\n",
      "2020-04-11 20:38:39.226261: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4fd37d0 executing computations on platform Host. Devices:\n",
      "2020-04-11 20:38:39.226325: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "2020-04-11 20:38:39.228514: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2020-04-11 20:38:39.487756: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x50cbbb0 executing computations on platform CUDA. Devices:\n",
      "2020-04-11 20:38:39.487867: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
      "2020-04-11 20:38:39.487922: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): Tesla K80, Compute Capability 3.7\n",
      "2020-04-11 20:38:39.489077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 0a0e:00:00.0\n",
      "2020-04-11 20:38:39.490091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: ea80:00:00.0\n",
      "2020-04-11 20:38:39.490414: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-04-11 20:38:39.491814: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-04-11 20:38:39.493007: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-04-11 20:38:39.493334: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-04-11 20:38:39.494928: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-04-11 20:38:39.496127: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-04-11 20:38:39.500235: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-04-11 20:38:39.503361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\n",
      "2020-04-11 20:38:39.503456: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-04-11 20:38:39.508103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-04-11 20:38:39.508169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 \n",
      "2020-04-11 20:38:39.508205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N N \n",
      "2020-04-11 20:38:39.508244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   N N \n",
      "2020-04-11 20:38:39.510660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:0 with 10804 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0a0e:00:00.0, compute capability: 3.7)\n",
      "2020-04-11 20:38:39.511866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:1 with 10804 MB memory) -> physical GPU (device: 1, name: Tesla K80, pci bus id: ea80:00:00.0, compute capability: 3.7)\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11500952908622908074\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 6572416246733751272\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 103531183482848762\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:1\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 6604244833782531162\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11329617920\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 6455301211849718716\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0a0e:00:00.0, compute capability: 3.7\"\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11329617920\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 17006939699669426103\n",
      "physical_device_desc: \"device: 1, name: Tesla K80, pci bus id: ea80:00:00.0, compute capability: 3.7\"\n",
      "]\n",
      "(5000, 256, 256, 1) (5000, 256, 256, 1)\n",
      "(5000, 256, 256, 1) (5000, 256, 256, 1)\n",
      "(5000, 256, 256, 1)\n",
      "(5000, 256, 256, 1)\n",
      "(5000, 256, 256, 1)\n",
      "(5000, 256, 256, 1)\n",
      "2020-04-11 20:39:09.336855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 0a0e:00:00.0\n",
      "2020-04-11 20:39:09.337707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: ea80:00:00.0\n",
      "2020-04-11 20:39:09.337800: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-04-11 20:39:09.337847: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-04-11 20:39:09.337888: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-04-11 20:39:09.337934: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-04-11 20:39:09.337976: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-04-11 20:39:09.338016: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-04-11 20:39:09.338058: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-04-11 20:39:09.340838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\n",
      "2020-04-11 20:39:09.342431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 0a0e:00:00.0\n",
      "2020-04-11 20:39:09.343215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: ea80:00:00.0\n",
      "2020-04-11 20:39:09.343281: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-04-11 20:39:09.343340: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-04-11 20:39:09.343394: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-04-11 20:39:09.343437: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-04-11 20:39:09.343479: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-04-11 20:39:09.343536: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-04-11 20:39:09.343578: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-04-11 20:39:09.346506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\n",
      "2020-04-11 20:39:09.346609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-04-11 20:39:09.346648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 \n",
      "2020-04-11 20:39:09.346680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N N \n",
      "2020-04-11 20:39:09.346715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   N N \n",
      "2020-04-11 20:39:09.348748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10804 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0a0e:00:00.0, compute capability: 3.7)\n",
      "2020-04-11 20:39:09.349533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10804 MB memory) -> physical GPU (device: 1, name: Tesla K80, pci bus id: ea80:00:00.0, compute capability: 3.7)\n",
      "2020-04-11 20:39:09.352790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 0a0e:00:00.0\n",
      "2020-04-11 20:39:09.353680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: ea80:00:00.0\n",
      "2020-04-11 20:39:09.353758: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-04-11 20:39:09.353806: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-04-11 20:39:09.353848: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-04-11 20:39:09.353890: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-04-11 20:39:09.353932: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-04-11 20:39:09.353979: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-04-11 20:39:09.354020: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-04-11 20:39:09.356946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\n",
      "2020-04-11 20:39:09.357032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-04-11 20:39:09.357069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 \n",
      "2020-04-11 20:39:09.357101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N N \n",
      "2020-04-11 20:39:09.357130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   N N \n",
      "2020-04-11 20:39:09.359327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:0 with 10804 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0a0e:00:00.0, compute capability: 3.7)\n",
      "2020-04-11 20:39:09.360119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:1 with 10804 MB memory) -> physical GPU (device: 1, name: Tesla K80, pci bus id: ea80:00:00.0, compute capability: 3.7)\n",
      "(None, 128, 128, 16) (None, 128, 128, 16)\n",
      "(None, 64, 64, 32) (None, 64, 64, 32)\n",
      "(None, 32, 32, 64) (None, 32, 32, 64)\n",
      "(None, 16, 16, 128) (None, 16, 16, 128)\n",
      "(None, 8, 8, 256) (None, 8, 8, 256)\n",
      "(None, 4, 4, 512) (None, 4, 4, 512)\n",
      "ENCDEC\n",
      "before concat: (deconv.shape,to_conc.shape) :  (None, 8, 8, 256) (None, 8, 8, 256)\n",
      "after concat: deconv.shape   (None, 8, 8, 512)\n",
      "(None, 8, 8, 512)\n",
      "before concat: (deconv.shape,to_conc.shape) :  (None, 16, 16, 128) (None, 16, 16, 128)\n",
      "after concat: deconv.shape   (None, 16, 16, 256)\n",
      "(None, 16, 16, 256)\n",
      "before concat: (deconv.shape,to_conc.shape) :  (None, 32, 32, 64) (None, 32, 32, 64)\n",
      "after concat: deconv.shape   (None, 32, 32, 128)\n",
      "(None, 32, 32, 128)\n",
      "before concat: (deconv.shape,to_conc.shape) :  (None, 64, 64, 32) (None, 64, 64, 32)\n",
      "after concat: deconv.shape   (None, 64, 64, 64)\n",
      "(None, 64, 64, 64)\n",
      "before concat: (deconv.shape,to_conc.shape) :  (None, 128, 128, 16) (None, 128, 128, 16)\n",
      "after concat: deconv.shape   (None, 128, 128, 32)\n",
      "(None, 128, 128, 32)\n",
      "(None, 256, 256, 1)\n",
      "final:  (None, 256, 256, 1)\n",
      "Train for 100 steps, validate for 100 steps\n",
      "Epoch 1/20\n",
      "2020-04-11 20:39:25.590247: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "b8aa51c0bbf34503828e2e9f3efeb94e000000:455:528 [1] NCCL INFO NET/Socket : Using [0]eth0:10.0.0.4<0>\n",
      "b8aa51c0bbf34503828e2e9f3efeb94e000000:455:528 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\n",
      "\n",
      "b8aa51c0bbf34503828e2e9f3efeb94e000000:455:528 [1] external/nccl_archive/src/misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\n",
      "NCCL version 2.4.7+cudaCUDA_MAJOR.CUDA_MINOR\n",
      "b8aa51c0bbf34503828e2e9f3efeb94e000000:455:564 [1] NCCL INFO Setting affinity for GPU 1 to 0fff\n",
      "b8aa51c0bbf34503828e2e9f3efeb94e000000:455:563 [0] NCCL INFO Setting affinity for GPU 0 to 0fff\n",
      "b8aa51c0bbf34503828e2e9f3efeb94e000000:455:563 [0] NCCL INFO Channel 00 :    0   1\n",
      "b8aa51c0bbf34503828e2e9f3efeb94e000000:455:563 [0] NCCL INFO Channel 01 :    0   1\n",
      "b8aa51c0bbf34503828e2e9f3efeb94e000000:455:564 [1] NCCL INFO Ring 00 : 1[1] -> 0[0] via direct shared memory\n",
      "b8aa51c0bbf34503828e2e9f3efeb94e000000:455:563 [0] NCCL INFO Ring 00 : 0[0] -> 1[1] via direct shared memory\n",
      "b8aa51c0bbf34503828e2e9f3efeb94e000000:455:563 [0] NCCL INFO Ring 01 : 0[0] -> 1[1] via direct shared memory\n",
      "b8aa51c0bbf34503828e2e9f3efeb94e000000:455:564 [1] NCCL INFO Ring 01 : 1[1] -> 0[0] via direct shared memory\n",
      "b8aa51c0bbf34503828e2e9f3efeb94e000000:455:563 [0] NCCL INFO Using 128 threads, Min Comp Cap 3, Trees disabled\n",
      "b8aa51c0bbf34503828e2e9f3efeb94e000000:455:563 [0] NCCL INFO comm 0x7f81bc0021a0 rank 0 nranks 2 cudaDev 0 nvmlDev 1 - Init COMPLETE\n",
      "b8aa51c0bbf34503828e2e9f3efeb94e000000:455:564 [1] NCCL INFO comm 0x7f81b0001340 rank 1 nranks 2 cudaDev 1 nvmlDev 0 - Init COMPLETE\n",
      "b8aa51c0bbf34503828e2e9f3efeb94e000000:455:560 [0] NCCL INFO Launch mode Group\n",
      "100/100 - 26s - loss: 0.8613 - accuracy: 1.5259e-08 - val_loss: 0.9162 - val_accuracy: 2.7466e-08\n",
      "Epoch 2/20\n",
      "100/100 - 14s - loss: 0.2545 - accuracy: 2.7466e-08 - val_loss: 0.3171 - val_accuracy: 3.0518e-08\n",
      "Epoch 3/20\n",
      "100/100 - 14s - loss: 0.1693 - accuracy: 2.7466e-08 - val_loss: 0.1409 - val_accuracy: 3.0518e-08\n",
      "Epoch 4/20\n",
      "100/100 - 13s - loss: 0.1340 - accuracy: 2.7466e-08 - val_loss: 0.0714 - val_accuracy: 3.0518e-08\n",
      "Epoch 5/20\n",
      "100/100 - 14s - loss: 0.1114 - accuracy: 2.7466e-08 - val_loss: 0.0438 - val_accuracy: 3.0518e-08\n",
      "Epoch 6/20\n",
      "100/100 - 14s - loss: 0.0965 - accuracy: 2.7466e-08 - val_loss: 0.0320 - val_accuracy: 3.0518e-08\n",
      "Epoch 7/20\n",
      "100/100 - 14s - loss: 0.0867 - accuracy: 2.7466e-08 - val_loss: 0.0244 - val_accuracy: 3.0518e-08\n",
      "Epoch 8/20\n",
      "100/100 - 14s - loss: 0.0797 - accuracy: 2.4414e-08 - val_loss: 0.0204 - val_accuracy: 3.0518e-08\n",
      "Epoch 9/20\n",
      "100/100 - 14s - loss: 0.0746 - accuracy: 2.7466e-08 - val_loss: 0.0166 - val_accuracy: 3.0518e-08\n",
      "Epoch 10/20\n",
      "100/100 - 13s - loss: 0.0706 - accuracy: 2.4414e-08 - val_loss: 0.0140 - val_accuracy: 3.0518e-08\n",
      "Epoch 11/20\n",
      "100/100 - 14s - loss: 0.0675 - accuracy: 2.7466e-08 - val_loss: 0.0126 - val_accuracy: 3.0518e-08\n",
      "Epoch 12/20\n",
      "100/100 - 14s - loss: 0.0648 - accuracy: 2.7466e-08 - val_loss: 0.0105 - val_accuracy: 3.0518e-08\n",
      "Epoch 13/20\n",
      "100/100 - 14s - loss: 0.0626 - accuracy: 2.7466e-08 - val_loss: 0.0089 - val_accuracy: 3.0518e-08\n",
      "Epoch 14/20\n",
      "100/100 - 13s - loss: 0.0607 - accuracy: 2.7466e-08 - val_loss: 0.0081 - val_accuracy: 3.0518e-08\n",
      "Epoch 15/20\n",
      "100/100 - 14s - loss: 0.0589 - accuracy: 2.7466e-08 - val_loss: 0.0078 - val_accuracy: 3.0518e-08\n",
      "Epoch 16/20\n",
      "100/100 - 13s - loss: 0.0574 - accuracy: 2.7466e-08 - val_loss: 0.0063 - val_accuracy: 3.0518e-08\n",
      "Epoch 17/20\n",
      "100/100 - 14s - loss: 0.0559 - accuracy: 2.7466e-08 - val_loss: 0.0054 - val_accuracy: 3.0518e-08\n",
      "Epoch 18/20\n",
      "100/100 - 14s - loss: 0.0546 - accuracy: 2.7466e-08 - val_loss: 0.0051 - val_accuracy: 3.0518e-08\n",
      "Epoch 19/20\n",
      "100/100 - 13s - loss: 0.0534 - accuracy: 2.7466e-08 - val_loss: 0.0046 - val_accuracy: 3.0518e-08\n",
      "Epoch 20/20\n",
      "100/100 - 13s - loss: 0.0522 - accuracy: 2.7466e-08 - val_loss: 0.0042 - val_accuracy: 3.0518e-08\n",
      "<tensorflow.python.keras.callbacks.History object at 0x7f8790115f60>\n",
      "Test loss: 0.004223384053260088\n",
      "Test accuracy: 3.051758e-08\n",
      "model saved in ./outputs/model folder\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 1.2218239307403564 seconds\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 455\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_b822616ab430925d5a2e6f9f15b2b7b54543eed65414c1dfaec6e96f4ee3e50b_d.txt\n",
      "===============================================================================================================\n",
      "\n",
      "Starting job release. Current time:2020-04-11T20:44:21.023746\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 938\n",
      "Job release is complete. Current time:2020-04-11T20:44:22.324361\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: tf-cluster-multi-gpu_1586637483_41828672\n",
      "Web View: https://ml.azure.com/experiments/tf-cluster-multi-gpu/runs/tf-cluster-multi-gpu_1586637483_41828672?wsid=/subscriptions/c1d0a0ea-bf6e-4c1c-8b55-f1bdb0208df8/resourcegroups/awe-cirrus-rg/workspaces/cirrustest2\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'tf-cluster-multi-gpu_1586637483_41828672',\n",
       " 'target': 'sn-gpu-cls-NC12',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2020-04-11T20:38:25.823078Z',\n",
       " 'endTimeUtc': '2020-04-11T20:44:32.897311Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': '15fc5b86-e726-428a-afdf-2d643e25df4b',\n",
       "  'azureml.git.repository_uri': 'https://github.com/returncode13/AzureML.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/returncode13/AzureML.git',\n",
       "  'azureml.git.branch': 'dev',\n",
       "  'mlflow.source.git.branch': 'dev',\n",
       "  'azureml.git.commit': '4cb1d1a63ee9d666f9b31647c6a1545e0c7ac969',\n",
       "  'mlflow.source.git.commit': '4cb1d1a63ee9d666f9b31647c6a1545e0c7ac969',\n",
       "  'azureml.git.dirty': 'True',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [],\n",
       " 'runDefinition': {'script': 'keras_mnist-gpu.py',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--batch-size',\n",
       "   '50',\n",
       "   '--first-layer-neurons',\n",
       "   '300',\n",
       "   '--second-layer-neurons',\n",
       "   '100',\n",
       "   '--learning-rate',\n",
       "   '0.001'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'sn-gpu-cls-NC12',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'Experiment tf-cluster-multi-gpu Environment',\n",
       "   'version': 'Autosave_2020-04-11T20:28:22Z_0cb92b9f',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': True,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults']}],\n",
       "     'name': 'project_environment'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'returncode13/tf-gpu-test:v2',\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': False},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}}},\n",
       " 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_b822616ab430925d5a2e6f9f15b2b7b54543eed65414c1dfaec6e96f4ee3e50b_d.txt': 'https://cirrustest28363900696.blob.core.windows.net/azureml/ExperimentRun/dcid.tf-cluster-multi-gpu_1586637483_41828672/azureml-logs/55_azureml-execution-tvmps_b822616ab430925d5a2e6f9f15b2b7b54543eed65414c1dfaec6e96f4ee3e50b_d.txt?sv=2019-02-02&sr=b&sig=KIS5Bl4B4YIoSW5GXlnvT2xrlQGuZMzdlB12E91Ywzw%3D&st=2020-04-11T20%3A34%3A33Z&se=2020-04-12T04%3A44%3A33Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_b822616ab430925d5a2e6f9f15b2b7b54543eed65414c1dfaec6e96f4ee3e50b_d.txt': 'https://cirrustest28363900696.blob.core.windows.net/azureml/ExperimentRun/dcid.tf-cluster-multi-gpu_1586637483_41828672/azureml-logs/65_job_prep-tvmps_b822616ab430925d5a2e6f9f15b2b7b54543eed65414c1dfaec6e96f4ee3e50b_d.txt?sv=2019-02-02&sr=b&sig=UnExXhnn41Bxc1uw7RPSEH3YmQVTxs%2Ft5njdCdhX4uE%3D&st=2020-04-11T20%3A34%3A33Z&se=2020-04-12T04%3A44%3A33Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://cirrustest28363900696.blob.core.windows.net/azureml/ExperimentRun/dcid.tf-cluster-multi-gpu_1586637483_41828672/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=FsXBDPpqaAFQb78hvACELrCoyfwkNnOqACzOiZT4JfM%3D&st=2020-04-11T20%3A34%3A33Z&se=2020-04-12T04%3A44%3A33Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_b822616ab430925d5a2e6f9f15b2b7b54543eed65414c1dfaec6e96f4ee3e50b_d.txt': 'https://cirrustest28363900696.blob.core.windows.net/azureml/ExperimentRun/dcid.tf-cluster-multi-gpu_1586637483_41828672/azureml-logs/75_job_post-tvmps_b822616ab430925d5a2e6f9f15b2b7b54543eed65414c1dfaec6e96f4ee3e50b_d.txt?sv=2019-02-02&sr=b&sig=%2FdTVBx%2FN2%2FDFwK0EZocWeZNAZV9gvuXVHE%2FGIUOQ5ak%3D&st=2020-04-11T20%3A34%3A33Z&se=2020-04-12T04%3A44%3A33Z&sp=r',\n",
       "  'azureml-logs/process_info.json': 'https://cirrustest28363900696.blob.core.windows.net/azureml/ExperimentRun/dcid.tf-cluster-multi-gpu_1586637483_41828672/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=UJulp5YkNkNpU1MxSWBU9mgz4WmSNK6Hh4LFPB47Ryc%3D&st=2020-04-11T20%3A34%3A33Z&se=2020-04-12T04%3A44%3A33Z&sp=r',\n",
       "  'azureml-logs/process_status.json': 'https://cirrustest28363900696.blob.core.windows.net/azureml/ExperimentRun/dcid.tf-cluster-multi-gpu_1586637483_41828672/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=p4POtPUfaYMsUK%2FPeby6u5CGYkWXeg3HG4psjyoS00U%3D&st=2020-04-11T20%3A34%3A33Z&se=2020-04-12T04%3A44%3A33Z&sp=r',\n",
       "  'logs/azureml/455_azureml.log': 'https://cirrustest28363900696.blob.core.windows.net/azureml/ExperimentRun/dcid.tf-cluster-multi-gpu_1586637483_41828672/logs/azureml/455_azureml.log?sv=2019-02-02&sr=b&sig=hGQYNTDZJrmWD3yy9yALAnrG7X2OBI7LbhaVBpw4T40%3D&st=2020-04-11T20%3A34%3A33Z&se=2020-04-12T04%3A44%3A33Z&sp=r',\n",
       "  'logs/azureml/job_prep_azureml.log': 'https://cirrustest28363900696.blob.core.windows.net/azureml/ExperimentRun/dcid.tf-cluster-multi-gpu_1586637483_41828672/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=KYhAA1q53giQmKy9ze2OPaLJPJpcXIwSsrCgYyk%2FI8g%3D&st=2020-04-11T20%3A34%3A33Z&se=2020-04-12T04%3A44%3A33Z&sp=r',\n",
       "  'logs/azureml/job_release_azureml.log': 'https://cirrustest28363900696.blob.core.windows.net/azureml/ExperimentRun/dcid.tf-cluster-multi-gpu_1586637483_41828672/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=CFa90IY9uqgEWGExg6jYHjj93IVwC0WnJMnLKKfDzmM%3D&st=2020-04-11T20%3A34%3A33Z&se=2020-04-12T04%3A44%3A33Z&sp=r'}}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the outputs of the training script, it prints out the Keras version number. Please make a note of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Run object\n",
    "**The Run object provides the interface to the run history -- both to the job and to the control plane (this notebook), and both while the job is running and after it has completed.** It provides a number of interesting features for instance:\n",
    "* `run.get_details()`: Provides a rich set of properties of the run\n",
    "* `run.get_metrics()`: Provides a dictionary with all the metrics that were reported for the Run\n",
    "* `run.get_file_names()`: List all the files that were uploaded to the run history for this Run. This will include the `outputs` and `logs` folder, azureml-logs and other logs, as well as files that were explicitly uploaded to the run using `run.upload_file()`\n",
    "\n",
    "Below are some examples -- please run through them and inspect their output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runId': 'tf-cluster-multi-gpu_1586630305_21445fac',\n",
       " 'target': 'sn-gpu-cls-NC12',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2020-04-11T18:38:47.390892Z',\n",
       " 'endTimeUtc': '2020-04-11T18:44:34.992251Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': '7b229fc4-48e2-472c-a15d-c70735e6f76a',\n",
       "  'azureml.git.repository_uri': 'https://github.com/returncode13/AzureML.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/returncode13/AzureML.git',\n",
       "  'azureml.git.branch': 'master',\n",
       "  'mlflow.source.git.branch': 'master',\n",
       "  'azureml.git.commit': '5aeeed9f6db36789aff15e45845b739c42d12804',\n",
       "  'mlflow.source.git.commit': '5aeeed9f6db36789aff15e45845b739c42d12804',\n",
       "  'azureml.git.dirty': 'True',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [],\n",
       " 'runDefinition': {'script': 'keras_mnist-gpu.py',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--batch-size',\n",
       "   '50',\n",
       "   '--first-layer-neurons',\n",
       "   '300',\n",
       "   '--second-layer-neurons',\n",
       "   '100',\n",
       "   '--learning-rate',\n",
       "   '0.001'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'sn-gpu-cls-NC12',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'Experiment tf-cluster-multi-gpu Environment',\n",
       "   'version': 'Autosave_2020-04-11T18:16:48Z_f823243d',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': True,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults']}],\n",
       "     'name': 'project_environment'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'returncode13/tf-gpu-test:v1',\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': False},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}}},\n",
       " 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_75440e6a10a6ca9c2c73a6e62f426036695052eb2290c30f0dc92b731e2a25f3_d.txt': 'https://cirrustest28363900696.blob.core.windows.net/azureml/ExperimentRun/dcid.tf-cluster-multi-gpu_1586630305_21445fac/azureml-logs/55_azureml-execution-tvmps_75440e6a10a6ca9c2c73a6e62f426036695052eb2290c30f0dc92b731e2a25f3_d.txt?sv=2019-02-02&sr=b&sig=8nkVNNudWPmlcxqqsvDqi4QglFDJOSX0uWgDuuD7Pww%3D&st=2020-04-11T18%3A34%3A36Z&se=2020-04-12T02%3A44%3A36Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_75440e6a10a6ca9c2c73a6e62f426036695052eb2290c30f0dc92b731e2a25f3_d.txt': 'https://cirrustest28363900696.blob.core.windows.net/azureml/ExperimentRun/dcid.tf-cluster-multi-gpu_1586630305_21445fac/azureml-logs/65_job_prep-tvmps_75440e6a10a6ca9c2c73a6e62f426036695052eb2290c30f0dc92b731e2a25f3_d.txt?sv=2019-02-02&sr=b&sig=kQ%2Ft4WWGgBfqKtTruFlB9Thu24rxHVXv%2Bg%2FjXj5DfBw%3D&st=2020-04-11T18%3A34%3A36Z&se=2020-04-12T02%3A44%3A36Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://cirrustest28363900696.blob.core.windows.net/azureml/ExperimentRun/dcid.tf-cluster-multi-gpu_1586630305_21445fac/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=e3Qt7mSKRNZqthLaa6loaSSWd5WNvfpuY2tua%2FVFy8c%3D&st=2020-04-11T18%3A34%3A36Z&se=2020-04-12T02%3A44%3A36Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_75440e6a10a6ca9c2c73a6e62f426036695052eb2290c30f0dc92b731e2a25f3_d.txt': 'https://cirrustest28363900696.blob.core.windows.net/azureml/ExperimentRun/dcid.tf-cluster-multi-gpu_1586630305_21445fac/azureml-logs/75_job_post-tvmps_75440e6a10a6ca9c2c73a6e62f426036695052eb2290c30f0dc92b731e2a25f3_d.txt?sv=2019-02-02&sr=b&sig=7Dh1tW1mWPOy307mHVjY6aS8tws7rCYg1pdTclecU%2Fc%3D&st=2020-04-11T18%3A34%3A36Z&se=2020-04-12T02%3A44%3A36Z&sp=r',\n",
       "  'azureml-logs/process_info.json': 'https://cirrustest28363900696.blob.core.windows.net/azureml/ExperimentRun/dcid.tf-cluster-multi-gpu_1586630305_21445fac/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=QiF4MI1EK5mes%2B0eyHK%2B2GbDX4qvwc4vm4ZCXNhfF2Q%3D&st=2020-04-11T18%3A34%3A36Z&se=2020-04-12T02%3A44%3A36Z&sp=r',\n",
       "  'azureml-logs/process_status.json': 'https://cirrustest28363900696.blob.core.windows.net/azureml/ExperimentRun/dcid.tf-cluster-multi-gpu_1586630305_21445fac/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=dja1udu5v%2B%2BgCTewlVog2Z6L5Q1B3nVBsDBUqZv2U5I%3D&st=2020-04-11T18%3A34%3A36Z&se=2020-04-12T02%3A44%3A36Z&sp=r'}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Loss': [0.8612848231196404,\n",
       "  0.2544753961265087,\n",
       "  0.16930606797337533,\n",
       "  0.13404045790433883,\n",
       "  0.11144404038786888,\n",
       "  0.09654842272400856,\n",
       "  0.08667242176830768,\n",
       "  0.07974897757172585,\n",
       "  0.07460214287042617,\n",
       "  0.07064146853983402,\n",
       "  0.06746331214904785,\n",
       "  0.06481637537479401,\n",
       "  0.06257621053606272,\n",
       "  0.06065903708338737,\n",
       "  0.05893784236162901,\n",
       "  0.05736836705356836,\n",
       "  0.05594342704862356,\n",
       "  0.05460468698292971,\n",
       "  0.05335312493145466,\n",
       "  0.05220870953053236],\n",
       " 'Accuracy': [1.525878978725359e-08,\n",
       "  2.7465819840699623e-08,\n",
       "  2.7465819840699623e-08,\n",
       "  2.7465819840699623e-08,\n",
       "  2.7465819840699623e-08,\n",
       "  2.7465819840699623e-08,\n",
       "  2.7465819840699623e-08,\n",
       "  2.4414061883248905e-08,\n",
       "  2.7465819840699623e-08,\n",
       "  2.4414061883248905e-08,\n",
       "  2.7465819840699623e-08,\n",
       "  2.7465819840699623e-08,\n",
       "  2.7465819840699623e-08,\n",
       "  2.7465819840699623e-08,\n",
       "  2.7465819840699623e-08,\n",
       "  2.7465819840699623e-08,\n",
       "  2.7465819840699623e-08,\n",
       "  2.7465819840699623e-08,\n",
       "  2.7465819840699623e-08,\n",
       "  2.7465819840699623e-08],\n",
       " 'Final test loss': 0.004223384053260088,\n",
       " 'Final test accuracy': 3.051757957450718e-08}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['azureml-logs/55_azureml-execution-tvmps_b822616ab430925d5a2e6f9f15b2b7b54543eed65414c1dfaec6e96f4ee3e50b_d.txt',\n",
       " 'azureml-logs/65_job_prep-tvmps_b822616ab430925d5a2e6f9f15b2b7b54543eed65414c1dfaec6e96f4ee3e50b_d.txt',\n",
       " 'azureml-logs/70_driver_log.txt',\n",
       " 'azureml-logs/75_job_post-tvmps_b822616ab430925d5a2e6f9f15b2b7b54543eed65414c1dfaec6e96f4ee3e50b_d.txt',\n",
       " 'azureml-logs/process_info.json',\n",
       " 'azureml-logs/process_status.json',\n",
       " 'logs/azureml/455_azureml.log',\n",
       " 'logs/azureml/job_prep_azureml.log',\n",
       " 'logs/azureml/job_release_azureml.log',\n",
       " 'outputs/model/model.h5',\n",
       " 'outputs/model/model.json']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_file_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the saved model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the training script, the Keras model is saved into two files, `model.json` and `model.h5`, in the `outputs/models` folder on the gpu-cluster AmlCompute node. Azure ML automatically uploaded anything written in the `./outputs` folder into run history file store. Subsequently, we can use the `run` object to download the model files. They are under the the `outputs/model` folder in the run history file store, and are downloaded into a local folder named `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model folder in the current directory\n",
    "os.makedirs('./model', exist_ok=True)\n",
    "\n",
    "for f in run.get_file_names():\n",
    "    if f.startswith('outputs/model'):\n",
    "        output_file_path = os.path.join('./model', f.split('/')[-1])\n",
    "        print('Downloading from {} to {} ...'.format(f, output_file_path))\n",
    "        run.download_file(name=f, output_file_path=output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on the test set\n",
    "Let's check the version of the local Keras. **Make sure it matches with the version number printed out in the training script. Otherwise you might not be able to load the model properly.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Keras version:\", tf.keras.__version__)\n",
    "print(\"Tensorflow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load the downloaded model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('model/model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model/model.h5\")\n",
    "print(\"Model loaded from disk.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed test dataset to the persisted model to get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "y_test_ohe = one_hot_encode(y_test, 10)\n",
    "y_hat = np.argmax(loaded_model.predict(X_test), axis=1)\n",
    "\n",
    "# print the first 30 labels and predictions\n",
    "print('labels:  \\t', y_test[:30])\n",
    "print('predictions:\\t', y_hat[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the overall accuracy by comparing the predicted value against the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy on the test set:\", np.average(y_hat == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intelligent hyperparameter tuning\n",
    "We have trained the model with one set of hyperparameters, now let's how we can do hyperparameter tuning by launching multiple runs on the cluster. First let's define the parameter space using random sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, HyperDriveConfig, PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive import choice, loguniform\n",
    "\n",
    "ps = RandomParameterSampling(\n",
    "    {\n",
    "        '--batch-size': choice(25, 50, 100),\n",
    "#         '--first-layer-neurons': choice(10, 50, 200, 300, 500),\n",
    "#         '--second-layer-neurons': choice(10, 50, 200, 500),\n",
    "#         '--learning-rate': loguniform(-6, -1)\n",
    "        '--epochs':choice(20,30,10)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create a new estimator without the above parameters since they will be passed in later by Hyperdrive configuration. Note we still need to keep the `data-folder` parameter since that's not a hyperparamter we will sweep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Estimator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b0e14abe3d39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m }\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m est = Estimator(source_directory=script_folder,\n\u001b[0m\u001b[1;32m     14\u001b[0m                  \u001b[0mscript_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscript_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                  \u001b[0mcompute_target\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Estimator' is not defined"
     ]
    }
   ],
   "source": [
    "# est = TensorFlow(source_directory=script_folder,\n",
    "#                  script_params={'--data-folder': dataset.as_named_input('mnist').as_mount()},\n",
    "#                  compute_target=compute_target,\n",
    "#                  entry_script='keras_mnist.py', \n",
    "#                  pip_packages=['keras==2.2.5','azureml-dataprep[pandas,fuse]','matplotlib'])\n",
    "\n",
    "script_params = {\n",
    "   \n",
    "    '--batch-size': 50,\n",
    "    '--epochs':20\n",
    "}\n",
    "\n",
    "est = Estimator(source_directory=script_folder,\n",
    "                 script_params=script_params,\n",
    "                 compute_target=compute_target, \n",
    "                 entry_script='keras_mnist-gpu.py', \n",
    "                 #pip_packages=['tensorflow==2.0','keras==2.2.5','azureml-dataprep[pandas,fuse]','matplotlib'],\n",
    "                 #framework_version=2.0,\n",
    "                # environ=some_file,\n",
    "                #use_docker=True,\n",
    "                #image_registry_details=container_registry,\n",
    "                custom_docker_image=\"returncode13/tf-gpu-test:v2\",\n",
    "                use_gpu=True,\n",
    "                user_managed=True\n",
    "                )\n",
    "\n",
    "# est = Estimator(source_directory=script_folder,\n",
    "#                  script_params={'--data-folder': dataset.as_named_input('mnist').as_mount()},\n",
    "#                  compute_target=compute_target, \n",
    "#                  entry_script='keras_mnist-gpu.py', \n",
    "#                  #pip_packages=['tensorflow==2.0','keras==2.2.5','azureml-dataprep[pandas,fuse]','matplotlib'],\n",
    "#                  #framework_version=2.0,\n",
    "#                 # environ=some_file,\n",
    "#                 use_docker=True,\n",
    "#                 #image_registry_details=container_registry,\n",
    "#                 #custom_docker_image=\"returncode13/tf-jupyter-comet\",\n",
    "#                  use_gpu=True\n",
    "#                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define an early termnination policy. The `BanditPolicy` basically states to check the job every 2 iterations. If the primary metric (defined later) falls outside of the top 10% range, Azure ML terminate the job. This saves us from continuing to explore hyperparameters that don't show promise of helping reach our target metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to configure a run configuration object, and specify the primary metric `Accuracy` that's recorded in your training runs. If you go back to visit the training script, you will notice that this value is being logged after every epoch (a full batch set). We also want to tell the service that we are looking to maximizing this value. We also set the number of samples to 20, and maximal concurrent job to 4, which is the same as the number of nodes in our computer cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdc = HyperDriveConfig(estimator=est, \n",
    "                       hyperparameter_sampling=ps, \n",
    "                       policy=policy, \n",
    "                       primary_metric_name='Accuracy', \n",
    "                       primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n",
    "                       max_total_runs=20,\n",
    "                       max_concurrent_runs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's launch the hyperparameter tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdr = exp.submit(config=hdc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a run history widget to show the progress. Be patient as this might take a while to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RunDetails(hdr).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdr.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warm start a Hyperparameter Tuning experiment and resuming child runs\n",
    "Often times, finding the best hyperparameter values for your model can be an iterative process, needing multiple tuning runs that learn from previous hyperparameter tuning runs. Reusing knowledge from these previous runs will accelerate the hyperparameter tuning process, thereby reducing the cost of tuning the model and will potentially improve the primary metric of the resulting model. When warm starting a hyperparameter tuning experiment with Bayesian sampling, trials from the previous run will be used as prior knowledge to intelligently pick new samples, so as to improve the primary metric. Additionally, when using Random or Grid sampling, any early termination decisions will leverage metrics from the previous runs to determine poorly performing training runs. \n",
    "\n",
    "Azure Machine Learning allows you to warm start your hyperparameter tuning run by leveraging knowledge from up to 5 previously completed hyperparameter tuning parent runs. \n",
    "\n",
    "Additionally, there might be occasions when individual training runs of a hyperparameter tuning experiment are cancelled due to budget constraints or fail due to other reasons. It is now possible to resume such individual training runs from the last checkpoint (assuming your training script handles checkpoints). Resuming an individual training run will use the same hyperparameter configuration and mount the storage used for that run. The training script should accept the \"--resume-from\" argument, which contains the checkpoint or model files from which to resume the training run. You can also resume individual runs as part of an experiment that spends additional budget on hyperparameter tuning. Any additional budget, after resuming the specified training runs is used for exploring additional configurations.\n",
    "\n",
    "For more information on warm starting and resuming hyperparameter tuning runs, please refer to the [Hyperparameter Tuning for Azure Machine Learning documentation](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-tune-hyperparameters) \n",
    "\n",
    "## Find and register best model\n",
    "When all the jobs finish, we can find out the one that has the highest accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = hdr.get_best_run_by_primary_metric()\n",
    "print(best_run.get_details()['runDefinition']['arguments'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's list the model files uploaded during the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_run.get_file_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then register the folder (and all files in it) as a model named `keras-dnn-mnist` under the workspace for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_run.register_model(model_name='keras-mlp-mnist', model_path='outputs/model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model in ACI\n",
    "Now we are ready to deploy the model as a web service running in Azure Container Instance [ACI](https://azure.microsoft.com/en-us/services/container-instances/). Azure Machine Learning accomplishes this by constructing a Docker image with the scoring logic and model baked in.\n",
    "### Create score.py\n",
    "First, we will create a scoring script that will be invoked by the web service call. \n",
    "\n",
    "* Note that the scoring script must have two required functions, `init()` and `run(input_data)`. \n",
    "  * In `init()` function, you typically load the model into a global object. This function is executed only once when the Docker container is started. \n",
    "  * In `run(input_data)` function, the model is used to predict a value based on the input data. The input and output to `run` typically use JSON as serialization and de-serialization format but you are not limited to that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from azureml.core.model import Model\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    \n",
    "    model_root = Model.get_model_path('keras-mlp-mnist')\n",
    "    # load json and create model\n",
    "    json_file = open(os.path.join(model_root, 'model.json'), 'r')\n",
    "    model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(model_json)\n",
    "    # load weights into new model\n",
    "    model.load_weights(os.path.join(model_root, \"model.h5\"))   \n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    \n",
    "def run(raw_data):\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    # make prediction\n",
    "    y_hat = np.argmax(model.predict(data), axis=1)\n",
    "    return y_hat.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create myenv.yml\n",
    "We also need to create an environment file so that Azure Machine Learning can install the necessary packages in the Docker image which are required by your scoring script. In this case, we need to specify conda packages `tensorflow` and `keras`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "cd = CondaDependencies.create()\n",
    "cd.add_tensorflow_conda_package()\n",
    "cd.add_conda_package('keras==2.2.5')\n",
    "cd.add_pip_package(\"azureml-defaults\")\n",
    "cd.save_to_file(base_directory='./', conda_file_path='myenv.yml')\n",
    "\n",
    "print(cd.serialize_to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy to ACI\n",
    "We are almost ready to deploy. Create the inference configuration and deployment configuration and deploy to ACI. This cell will run for about 7-8 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.environment import Environment\n",
    "\n",
    "\n",
    "myenv = Environment.from_conda_specification(name=\"myenv\", file_path=\"myenv.yml\")\n",
    "inference_config = InferenceConfig(entry_script=\"score.py\", environment=myenv)\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1,\n",
    "                                               auth_enabled=True, # this flag generates API keys to secure access\n",
    "                                               memory_gb=1,\n",
    "                                               tags={'name': 'mnist', 'framework': 'Keras'},\n",
    "                                               description='Keras MLP on MNIST')\n",
    "\n",
    "service = Model.deploy(workspace=ws, \n",
    "                           name='keras-mnist-svc', \n",
    "                           models=[model], \n",
    "                           inference_config=inference_config, \n",
    "                           deployment_config=aciconfig)\n",
    "\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip: If something goes wrong with the deployment, the first thing to look at is the logs from the service by running the following command:** `print(service.get_logs())`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the scoring web service endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the deployed model\n",
    "Let's test the deployed model. Pick 30 random samples from the test set, and send it to the web service hosted in ACI. Note here we are using the `run` API in the SDK to invoke the service. You can also make raw HTTP calls using any HTTP tool such as curl.\n",
    "\n",
    "After the invocation, we print the returned predictions and plot them along with the input images. Use red font color and inversed image (white on black) to highlight the misclassified samples. Note since the model accuracy is pretty high, you might have to run the below cell a few times before you can see a misclassified sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# find 30 random samples from test set\n",
    "n = 30\n",
    "sample_indices = np.random.permutation(X_test.shape[0])[0:n]\n",
    "\n",
    "test_samples = json.dumps({\"data\": X_test[sample_indices].tolist()})\n",
    "test_samples = bytes(test_samples, encoding='utf8')\n",
    "\n",
    "# predict using the deployed model\n",
    "result = service.run(input_data=test_samples)\n",
    "\n",
    "# compare actual value vs. the predicted values:\n",
    "i = 0\n",
    "plt.figure(figsize = (20, 1))\n",
    "\n",
    "for s in sample_indices:\n",
    "    plt.subplot(1, n, i + 1)\n",
    "    plt.axhline('')\n",
    "    plt.axvline('')\n",
    "    \n",
    "    # use different color for misclassified sample\n",
    "    font_color = 'red' if y_test[s] != result[i] else 'black'\n",
    "    clr_map = plt.cm.gray if y_test[s] != result[i] else plt.cm.Greys\n",
    "    \n",
    "    plt.text(x=10, y=-10, s=y_test[s], fontsize=18, color=font_color)\n",
    "    plt.imshow(X_test[s].reshape(28, 28), cmap=clr_map)\n",
    "    \n",
    "    i = i + 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retrieve the API keys used for accessing the HTTP endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the API keys. Two keys were generated.\n",
    "key1, Key2 = service.get_keys()\n",
    "print(key1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now send construct raw HTTP request and send to the service. Don't forget to add key to the HTTP header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# send a random row from the test set to score\n",
    "random_index = np.random.randint(0, len(X_test)-1)\n",
    "input_data = \"{\\\"data\\\": [\" + str(list(X_test[random_index])) + \"]}\"\n",
    "\n",
    "headers = {'Content-Type':'application/json', 'Authorization': 'Bearer ' + key1}\n",
    "\n",
    "resp = requests.post(service.scoring_uri, input_data, headers=headers)\n",
    "\n",
    "print(\"POST to url\", service.scoring_uri)\n",
    "#print(\"input data:\", input_data)\n",
    "print(\"label:\", y_test[random_index])\n",
    "print(\"prediction:\", resp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the workspace after the web service was deployed. You should see \n",
    "* a registered model named 'keras-mlp-mnist' and with the id 'model:1'  \n",
    "* a webservice called 'keras-mnist-svc' with some scoring URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ws.models['keras-mlp-mnist']\n",
    "print(\"Model: {}, ID: {}\".format('keras-mlp-mnist', model.id))\n",
    "    \n",
    "webservice = ws.webservices['keras-mnist-svc']\n",
    "print(\"Webservice: {}, scoring URI: {}\".format('keras-mnist-svc', webservice.scoring_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "You can delete the ACI deployment with a simple delete API call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "swatig"
   }
  ],
  "categories": [
   "how-to-use-azureml",
   "training-with-deep-learning"
  ],
  "category": "training",
  "compute": [
   "AML Compute"
  ],
  "datasets": [
   "MNIST"
  ],
  "deployment": [
   "Azure Container Instance"
  ],
  "exclude_from_index": false,
  "framework": [
   "TensorFlow"
  ],
  "friendly_name": "Train a DNN using hyperparameter tuning and deploying with Keras",
  "index_order": 1,
  "kernelspec": {
   "display_name": "azml120",
   "language": "python",
   "name": "azml120"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "tags": [
   "None"
  ],
  "task": "Create a multi-class classifier"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
